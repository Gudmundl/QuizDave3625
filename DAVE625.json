[
    {
        "question": "Which institutional sector produced nearly 90% of notable AI models in 2024?",
        "options": [
            "Academia",
            "Government",
            "Industry",
            "Non-profit organizations"
        ],
        "correct": "Industry",
         "explanation": "Industry's lead in notable model development grew significantly, rising from 60% in 2023 to nearly 90% in 2024[cite: 62, 95].",
        "topic": "Research and Development Trends"
    },
    {
        "question": "Which country produced the highest total of AI publications and citations in 2023?",
        "options": [
            "United States",
            "China",
            "United Kingdom",
            "India"
        ],
        "correct": "China",
         "explanation": "China led the world in AI publication volume (23.2%) and citations (22.6%) in 2023[cite: 98].",
        "topic": "Research and Development Trends"
    },
    {
        "question": "How did the performance gap between top open-weight and closed-weight models change between January 2024 and February 2025?",
        "options": [
            "It increased from 1.7% to 8.0%",
            "It stayed constant at 5.4%",
            "It narrowed from 8.0% to 1.7%",
            "It disappeared entirely (0%)"
        ],
        "correct": "It narrowed from 8.0% to 1.7%",
         "explanation": "Leading open-weight models have rapidly caught up to closed-weight counterparts on the Chatbot Arena Leaderboard[cite: 125, 126].",
        "topic": "Technical Performance"
    },
    {
        "question": "What was the percentage-point increase in AI performance on the SWE-bench between 2023 and 2024?",
        "options": [
            "18.8 points",
            "48.9 points",
            "67.3 points",
            "22.3 points"
        ],
        "correct": "67.3 points",
         "explanation": "AI performance on the software engineering benchmark SWE-bench saw a massive leap of 67.3 percentage points in just one year[cite: 30, 876].",
        "topic": "Technical Performance"
    },
    {
        "question": "Which new reasoning paradigm was introduced in 2024 to improve AI performance on complex mathematical tasks?",
        "options": [
            "Reinforcement learning from human feedback",
            "Test-time compute",
            "Zero-shot prompting",
            "Low-rank adaptation"
        ],
        "correct": "Test-time compute",
         "explanation": "Models like OpenAI’s o1 use test-time compute to iteratively reason through outputs, significantly boosting math performance[cite: 132, 133].",
        "topic": "Technical Performance"
    },
    {
        "question": "In 2024, how much private AI investment did the United States record compared to China?",
        "options": [
            "Nearly 2 times as much",
            "Nearly 5 times as much",
            "Nearly 12 times as much",
            "Nearly 24 times as much"
        ],
        "correct": "Nearly 12 times as much",
         "explanation": "U.S. private AI investment reached $109.1 billion, which is nearly 12 times China's $9.3 billion[cite: 35, 881].",
        "topic": "Economy and Investment"
    },
    {
        "question": "What percentage of organizations reported using AI in 2024?",
        "options": [
            "40%",
            "55%",
            "78%",
            "90%"
        ],
        "correct": "78%",
         "explanation": "Business adoption of AI accelerated from 55% in 2023 to 78% in 2024[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "The inference cost for a system performing at the GPT-3.5 level dropped by how much between 2022 and 2024?",
        "options": [
            "10-fold",
            "50-fold",
            "150-fold",
            "Over 280-fold"
        ],
        "correct": "Over 280-fold",
         "explanation": "Costs dropped from $20.00 to $0.07 per million tokens, representing a more than 280-fold reduction[cite: 50, 108].",
        "topic": "AI Hardware and Efficiency"
    },
    {
        "question": "How often does the training compute for notable AI models currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 2 years"
        ],
        "correct": "Every 5 months",
         "explanation": "New research indicates that training compute requirements are doubling approximately every five months[cite: 63, 106].",
        "topic": "AI Hardware and Efficiency"
    },
    {
        "question": "Which country reported the highest level of AI optimism in 2024, with 83% seeing AI as more beneficial than harmful?",
        "options": [
            "United States",
            "Canada",
            "China",
            "Germany"
        ],
        "correct": "China",
         "explanation": "China leads global AI optimism at 83%, whereas countries like the U.S. and Canada remain below 40%[cite: 47, 48, 896].",
        "topic": "Public Opinion"
    },
    {
        "question": "In 2023, how many AI-enabled medical devices were approved by the FDA?",
        "options": [
            "6",
            "59",
            "150",
            "223"
        ],
        "correct": "223",
         "explanation": "The FDA approved 223 AI-enabled medical devices in 2023, a massive increase from only six in 2015[cite: 33, 879].",
        "topic": "Science and Medicine"
    },
    {
        "question": "Which 2024 AI model had the highest recorded carbon emissions during training at 8,930 tons?",
        "options": [
            "GPT-3",
            "GPT-4",
            "Llama 3.1 405B",
            "Gemini 1.5 Flash"
        ],
        "correct": "Llama 3.1 405B",
         "explanation": "Llama 3.1 405B training emitted 8,930 tons of carbon, compared to 5,184 tons for GPT-4[cite: 118].",
        "topic": "AI Hardware and Efficiency"
    },
    {
        "question": "What is the primary reason many African countries face limited access to computer science education?",
        "options": [
            "Lack of interest from students",
            "Government bans on AI",
            "Basic infrastructure gaps like electricity",
            "High cost of software licenses"
        ],
        "correct": "Basic infrastructure gaps like electricity",
         "explanation": "Despite progress in curriculum planning, basic infrastructure like electricity remains a barrier in many African nations[cite: 59, 908].",
        "topic": "Education"
    },
    {
        "question": "How many AI-related regulations were introduced by U.S. federal agencies in 2024?",
        "options": [
            "15",
            "25",
            "59",
            "122"
        ],
        "correct": "59",
         "explanation": "U.S. federal agencies more than doubled their AI-related regulations to 59 in 2024[cite: 54, 903].",
        "topic": "Policy and Governance"
    },
    {
        "question": "On which rigorous academic benchmark does the top AI system currently score only 8.80%?",
        "options": [
            "MMLU",
            "GPQA",
            "Humanity's Last Exam",
            "FrontierMath"
        ],
        "correct": "Humanity's Last Exam",
         "explanation": "Humanity's Last Exam is a rigorous test where even the best AI systems currently struggle, scoring under 9%[cite: 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "Which organization's robotaxi fleet provides over 150,000 autonomous rides each week in the U.S.?",
        "options": [
            "Baidu",
            "Tesla",
            "Waymo",
            "Uber"
        ],
        "correct": "Waymo",
         "explanation": "Waymo is cited as a large U.S. operator providing over 150,000 autonomous rides weekly[cite: 33, 879].",
        "topic": "Everyday AI Integration"
    },
    {
        "question": "What was the growth rate of AI patenting between 2022 and 2023?",
        "options": [
            "5.4%",
            "18.7%",
            "21.3%",
            "29.6%"
        ],
        "correct": "29.6%",
         "explanation": "AI patents grew significantly by 29.6% in a single year as of 2023[cite: 112].",
        "topic": "Research and Development Trends"
    },
    {
        "question": "Which country leads in AI patents per capita according to the 2025 report?",
        "options": [
            "China",
            "United States",
            "South Korea",
            "Japan"
        ],
        "correct": "South Korea",
         "explanation": "While China leads in total patents, South Korea and Luxembourg are top producers on a per capita basis[cite: 113].",
        "topic": "Research and Development Trends"
    },
    {
        "question": "According to the report, what is the 'saturation' issue in AI benchmarking?",
        "options": [
            "Models are becoming too large to run benchmarks",
            "Traditional benchmarks like MMLU are becoming too easy for top models",
            "Benchmarks are too expensive to administer",
            "There is not enough data to create new benchmarks"
        ],
        "correct": "Traditional benchmarks like MMLU are becoming too easy for top models",
         "explanation": "The saturation of traditional benchmarks has pushed researchers to develop more challenging evaluations like FrontierMath[cite: 136].",
        "topic": "Technical Performance"
    },
    {
        "question": "What is the primary challenge for AI models in 'high-stakes' settings as noted in the report?",
        "options": [
            "High energy consumption",
            "Lack of data",
            "Failure to reliably solve logic tasks even with provably correct solutions",
            "Slow processing speeds"
        ],
        "correct": "Failure to reliably solve logic tasks even with provably correct solutions",
         "explanation": "AI models still struggle with complex reasoning benchmarks like PlanBench, limiting their use where precision is critical[cite: 68, 921].",
        "topic": "Responsible AI"
    },

    {
        "question": "What percentage of computer science publications were AI-related in 2023?",
        "options": [
            "10.2%",
            "21.6%",
            "35.4%",
            "41.8%"
        ],
        "correct": "41.8%",
         "explanation": "AI's share of computer science publications grew from 21.6% in 2013 to 41.8% in 2023[cite: 102].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "Which institutional sector has remained the leading producer of the 'top 100' highly cited AI publications over the last three years?",
        "options": [
            "Industry",
            "Government",
            "Academia",
            "Non-profit Research"
        ],
        "correct": "Academia",
         "explanation": "While industry leads in model development, academia is the top producer of highly influential (top 100) research[cite: 96].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "By what factor did AI publication totals grow between 2013 and 2023?",
        "options": [
            "Nearly doubled",
            "Nearly tripled",
            "Exactly quadrupled",
            "Tenfold increase"
        ],
        "correct": "Nearly tripled",
         "explanation": "Total AI publications increased from approximately 102,000 in 2013 to over 242,000 in 2023[cite: 101].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "In 2024, how many notable AI models were produced by European institutions compared to the United States?",
        "options": [
            "3 models vs 40 models",
            "15 models vs 40 models",
            "10 models vs 25 models",
            "3 models vs 15 models"
        ],
        "correct": "3 models vs 40 models",
         "explanation": "U.S.-based institutions produced 40 notable models, significantly surpassing Europe's total of three[cite: 103].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "What was the performance gap between U.S. and Chinese models on the HumanEval benchmark at the end of 2024?",
        "options": [
            "31.6 percentage points",
            "17.5 percentage points",
            "3.7 percentage points",
            "0.3 percentage points"
        ],
        "correct": "3.7 percentage points",
         "explanation": "The gap on HumanEval narrowed from 31.6 points in 2023 to just 3.7 points by the end of 2024[cite: 128, 129].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "Which country accounts for nearly 70% of all AI patent grants as of 2023?",
        "options": [
            "United States",
            "Japan",
            "China",
            "South Korea"
        ],
        "correct": "China",
         "explanation": "China leads in total AI patents, accounting for 69.7% of all grants globally[cite: 113].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "According to the report, which country stands out as a top AI patent producer on a 'per capita' basis?",
        "options": [
            "China",
            "India",
            "Luxembourg",
            "Brazil"
        ],
        "correct": "Luxembourg",
         "explanation": "While China leads in totals, South Korea and Luxembourg are top producers on a per capita basis[cite: 113].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "How many AI-enabled medical devices did the FDA approve in 2015 compared to 2023?",
        "options": [
            "6 in 2015 vs 223 in 2023",
            "50 in 2015 vs 150 in 2023",
            "0 in 2015 vs 100 in 2023",
            "12 in 2015 vs 88 in 2023"
        ],
        "correct": "6 in 2015 vs 223 in 2023",
         "explanation": "FDA approvals for AI medical devices rose from just six in 2015 to 223 in 2023[cite: 33].",
        "topic": "AI in Medicine and Science"
    },
    {
        "question": "Which 2024 scientific milestone reflected AI's impact on chemistry?",
        "options": [
            "The Turing Award for deep learning",
            "A Nobel Prize for protein folding applications",
            "The Fields Medal for AI-driven proofs",
            "A Nobel Prize for reinforcement learning"
        ],
        "correct": "A Nobel Prize for protein folding applications",
         "explanation": "A 2024 Nobel Prize in Chemistry recognized AI's application to protein folding[cite: 66].",
        "topic": "AI in Medicine and Science"
    },
    {
        "question": "What is the recorded performance of top AI systems on the 'FrontierMath' benchmark?",
        "options": [
            "90%",
            "50%",
            "8.8%",
            "2%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely difficult benchmark where current AI systems solve only 2% of problems[cite: 138].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "On the 'BigCodeBench' coding benchmark, what is the human standard for success compared to the current top AI performance?",
        "options": [
            "97% (Human) vs 35.5% (AI)",
            "100% (Human) vs 71.7% (AI)",
            "80% (Human) vs 50% (AI)",
            "95% (Human) vs 15% (AI)"
        ],
        "correct": "97% (Human) vs 35.5% (AI)",
         "explanation": "AI systems currently achieve a 35.5% success rate on BigCodeBench, far below the 97% human standard[cite: 139].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "The 'Humanity's Last Exam' benchmark is characterized by which top system score?",
        "options": [
            "74.4%",
            "48.9%",
            "18.8%",
            "8.80%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a rigorous test where the top AI system currently scores just 8.80%[cite: 137].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "By what factor did the cost of querying a GPT-3.5-level system drop between late 2022 and late 2024?",
         "explanation": "The cost dropped from $20.00 to $0.07 per million tokens, a more than 280-fold reduction[cite: 108].",
        "options": [
            "10-fold",
            "100-fold",
            "More than 280-fold",
            "Exactly 500-fold"
        ],
        "correct": "More than 280-fold",
        "topic": "Inference and Operational Costs"
    },
    {
        "question": "What is the typical range of annual price performance improvement for machine learning hardware?",
        "options": [
            "10%",
            "30%",
            "50%",
            "75%"
        ],
        "correct": "30%",
         "explanation": "Hardware price performance has improved with costs dropping by 30% per year[cite: 116].",
        "topic": "AI Hardware and Energy"
    },
    {
        "question": "According to the 2025 report, how often do dataset sizes for training Large Language Models (LLMs) currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 8 months",
         "explanation": "Research indicates that training dataset sizes for LLMs double every eight months[cite: 106].",
        "topic": "Training Data and Compute"
    },
    {
        "question": "The power required for training notable AI models is increasing at what annual rate?",
        "options": [
            "It is doubling annually",
            "It is decreasing by 40% annually",
            "It is staying flat due to efficiency",
            "It is increasing by 10% annually"
        ],
        "correct": "It is doubling annually",
         "explanation": "The report notes that power required for training is doubling on an annual basis[cite: 106].",
        "topic": "AI Hardware and Energy"
    },
    {
        "question": "Which specific 2024 model released by OpenAI utilizes 'test-time compute' to improve math performance?",
        "options": [
            "GPT-4o",
            "o1",
            "SORA",
            "DALL-E 3"
        ],
        "correct": "o1",
         "explanation": "OpenAI's o1 model uses test-time compute to reason through outputs, significantly outperforming GPT-4o on math exams[cite: 133, 134].",
        "topic": "Technical Innovation"
    },
    {
        "question": "Compared to GPT-4o, how much slower is the o1 model due to its reasoning process?",
        "options": [
            "2 times slower",
            "5 times slower",
            "10 times slower",
            "30 times slower"
        ],
        "correct": "30 times slower",
         "explanation": "While more capable at reasoning, the o1 model is approximately 30 times slower than GPT-4o[cite: 135].",
        "topic": "Technical Innovation"
    },
    {
        "question": "What was the private AI investment in the United Kingdom in 2024?",
        "options": [
            "$109.1 billion",
            "$33.9 billion",
            "$9.3 billion",
            "$4.5 billion"
        ],
        "correct": "$4.5 billion",
         "explanation": "The U.K. recorded $4.5 billion in private AI investment, which is 24 times less than the U.S. total[cite: 35].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Global private investment in 'Generative AI' specifically reached what amount in 2024?",
        "options": [
            "$10.5 billion",
            "$33.9 billion",
            "$109.1 billion",
            "$200 billion"
        ],
        "correct": "$33.9 billion",
         "explanation": "Generative AI attracted $33.9 billion globally in private investment, an 18.7% increase from the previous year[cite: 36].",
        "topic": "Economy and Investment"
    },
    
    {
        "question": "What percentage of computer science publications were AI-related in 2023?",
        "options": [
            "10.2%",
            "21.6%",
            "35.4%",
            "41.8%"
        ],
        "correct": "41.8%",
         "explanation": "AI's share of computer science publications grew from 21.6% in 2013 to 41.8% in 2023[cite: 102].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "Which institutional sector has remained the leading producer of the 'top 100' highly cited AI publications over the last three years?",
        "options": [
            "Industry",
            "Government",
            "Academia",
            "Non-profit Research"
        ],
        "correct": "Academia",
         "explanation": "While industry leads in model development, academia is the top producer of highly influential (top 100) research[cite: 96].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "By what factor did AI publication totals grow between 2013 and 2023?",
        "options": [
            "Nearly doubled",
            "Nearly tripled",
            "Exactly quadrupled",
            "Tenfold increase"
        ],
        "correct": "Nearly tripled",
         "explanation": "Total AI publications increased from approximately 102,000 in 2013 to over 242,000 in 2023[cite: 101].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "In 2024, how many notable AI models were produced by European institutions compared to the United States?",
        "options": [
            "3 models vs 40 models",
            "15 models vs 40 models",
            "10 models vs 25 models",
            "3 models vs 15 models"
        ],
        "correct": "3 models vs 40 models",
         "explanation": "U.S.-based institutions produced 40 notable models, significantly surpassing Europe's total of three[cite: 103].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "What was the performance gap between U.S. and Chinese models on the HumanEval benchmark at the end of 2024?",
        "options": [
            "31.6 percentage points",
            "17.5 percentage points",
            "3.7 percentage points",
            "0.3 percentage points"
        ],
        "correct": "3.7 percentage points",
         "explanation": "The gap on HumanEval narrowed from 31.6 points in 2023 to just 3.7 points by the end of 2024[cite: 128, 129].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "Which country accounts for nearly 70% of all AI patent grants as of 2023?",
        "options": [
            "United States",
            "Japan",
            "China",
            "South Korea"
        ],
        "correct": "China",
         "explanation": "China leads in total AI patents, accounting for 69.7% of all grants globally[cite: 113].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "According to the report, which country stands out as a top AI patent producer on a 'per capita' basis?",
        "options": [
            "China",
            "India",
            "Luxembourg",
            "Brazil"
        ],
        "correct": "Luxembourg",
         "explanation": "While China leads in totals, South Korea and Luxembourg are top producers on a per capita basis[cite: 113].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "How many AI-enabled medical devices did the FDA approve in 2015 compared to 2023?",
        "options": [
            "6 in 2015 vs 223 in 2023",
            "50 in 2015 vs 150 in 2023",
            "0 in 2015 vs 100 in 2023",
            "12 in 2015 vs 88 in 2023"
        ],
        "correct": "6 in 2015 vs 223 in 2023",
         "explanation": "FDA approvals for AI medical devices rose from just six in 2015 to 223 in 2023[cite: 33].",
        "topic": "AI in Medicine and Science"
    },
    {
        "question": "Which 2024 scientific milestone reflected AI's impact on chemistry?",
        "options": [
            "The Turing Award for deep learning",
            "A Nobel Prize for protein folding applications",
            "The Fields Medal for AI-driven proofs",
            "A Nobel Prize for reinforcement learning"
        ],
        "correct": "A Nobel Prize for protein folding applications",
         "explanation": "A 2024 Nobel Prize in Chemistry recognized AI's application to protein folding[cite: 66].",
        "topic": "AI in Medicine and Science"
    },
    {
        "question": "What is the recorded performance of top AI systems on the 'FrontierMath' benchmark?",
        "options": [
            "90%",
            "50%",
            "8.8%",
            "2%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely difficult benchmark where current AI systems solve only 2% of problems[cite: 138].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "On the 'BigCodeBench' coding benchmark, what is the human standard for success compared to the current top AI performance?",
        "options": [
            "97% (Human) vs 35.5% (AI)",
            "100% (Human) vs 71.7% (AI)",
            "80% (Human) vs 50% (AI)",
            "95% (Human) vs 15% (AI)"
        ],
        "correct": "97% (Human) vs 35.5% (AI)",
         "explanation": "AI systems currently achieve a 35.5% success rate on BigCodeBench, far below the 97% human standard[cite: 139].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "The 'Humanity's Last Exam' benchmark is characterized by which top system score?",
        "options": [
            "74.4%",
            "48.9%",
            "18.8%",
            "8.80%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a rigorous test where the top AI system currently scores just 8.80%[cite: 137].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "By what factor did the cost of querying a GPT-3.5-level system drop between late 2022 and late 2024?",
         "explanation": "The cost dropped from $20.00 to $0.07 per million tokens, a more than 280-fold reduction[cite: 108].",
        "options": [
            "10-fold",
            "100-fold",
            "More than 280-fold",
            "Exactly 500-fold"
        ],
        "correct": "More than 280-fold",
        "topic": "Inference and Operational Costs"
    },
    {
        "question": "What is the typical range of annual price performance improvement for machine learning hardware?",
        "options": [
            "10%",
            "30%",
            "50%",
            "75%"
        ],
        "correct": "30%",
         "explanation": "Hardware price performance has improved with costs dropping by 30% per year[cite: 116].",
        "topic": "AI Hardware and Energy"
    },
    {
        "question": "According to the 2025 report, how often do dataset sizes for training Large Language Models (LLMs) currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 8 months",
         "explanation": "Research indicates that training dataset sizes for LLMs double every eight months[cite: 106].",
        "topic": "Training Data and Compute"
    },
    {
        "question": "The power required for training notable AI models is increasing at what annual rate?",
        "options": [
            "It is doubling annually",
            "It is decreasing by 40% annually",
            "It is staying flat due to efficiency",
            "It is increasing by 10% annually"
        ],
        "correct": "It is doubling annually",
         "explanation": "The report notes that power required for training is doubling on an annual basis[cite: 106].",
        "topic": "AI Hardware and Energy"
    },
    {
        "question": "Which specific 2024 model released by OpenAI utilizes 'test-time compute' to improve math performance?",
        "options": [
            "GPT-4o",
            "o1",
            "SORA",
            "DALL-E 3"
        ],
        "correct": "o1",
         "explanation": "OpenAI's o1 model uses test-time compute to reason through outputs, significantly outperforming GPT-4o on math exams[cite: 133, 134].",
        "topic": "Technical Innovation"
    },
    {
        "question": "Compared to GPT-4o, how much slower is the o1 model due to its reasoning process?",
        "options": [
            "2 times slower",
            "5 times slower",
            "10 times slower",
            "30 times slower"
        ],
        "correct": "30 times slower",
         "explanation": "While more capable at reasoning, the o1 model is approximately 30 times slower than GPT-4o[cite: 135].",
        "topic": "Technical Innovation"
    },
    {
        "question": "What was the private AI investment in the United Kingdom in 2024?",
        "options": [
            "$109.1 billion",
            "$33.9 billion",
            "$9.3 billion",
            "$4.5 billion"
        ],
        "correct": "$4.5 billion",
         "explanation": "The U.K. recorded $4.5 billion in private AI investment, which is 24 times less than the U.S. total[cite: 35].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Global private investment in 'Generative AI' specifically reached what amount in 2024?",
        "options": [
            "$10.5 billion",
            "$33.9 billion",
            "$109.1 billion",
            "$200 billion"
        ],
        "correct": "$33.9 billion",
         "explanation": "Generative AI attracted $33.9 billion globally in private investment, an 18.7% increase from the previous year[cite: 36].",
        "topic": "Economy and Investment"
    }
,
    {
        "question": "What percentage of 'notable' AI models in 2024 were produced by the industry sector?",
        "options": [
            "30%",
            "60%",
            "75%",
            "90%"
        ],
        "correct": "90%",
         "explanation": "Industry's lead in notable model development grew significantly from 60% in 2023 to nearly 90% in 2024[cite: 62, 95].",
        "topic": "Research and Development"
    },
    {
        "question": "According to the 2025 report, which sector remains the top producer of highly cited (top 100) AI research papers?",
        "options": [
            "Industry",
            "Government",
            "Academia",
            "Non-profit Organizations"
        ],
        "correct": "Academia",
         "explanation": "While industry leads in model development, academia has remained the leading producer of highly cited publications over the past three years[cite: 62, 96].",
        "topic": "Research and Development"
    },
    {
        "question": "By how many percentage points did AI performance on the software engineering benchmark 'SWE-bench' increase between 2023 and 2024?",
        "options": [
            "18.8 points",
            "48.9 points",
            "67.3 points",
            "8.8 points"
        ],
        "correct": "67.3 points",
         "explanation": "AI performance on the SWE-bench saw a massive leap of 67.3 percentage points in just one year[cite: 30, 876].",
        "topic": "Technical Performance"
    },
    {
        "question": "What is the top AI system's current score on the rigorous 'Humanity's Last Exam' benchmark?",
        "options": [
            "2.00%",
            "8.80%",
            "35.50%",
            "74.40%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a rigorous academic test where the top AI system currently scores only 8.80%[cite: 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "How did the performance gap between top open-weight and closed-weight models change from January 2024 to February 2025?",
        "options": [
            "It widened from 1.7% to 8.0%",
            "It narrowed from 8.0% to 1.7%",
            "It remained constant at 5.4%",
            "It disappeared entirely (0%)"
        ],
        "correct": "It narrowed from 8.0% to 1.7%",
         "explanation": "The gap between leading open-weight and closed-weight models narrowed significantly from 8.0% to just 1.7% in one year[cite: 51, 126].",
        "topic": "Technical Performance"
    },
    {
        "question": "In 2024, how much private AI investment did the United States record compared to China?",
        "options": [
            "Nearly 2 times as much",
            "Nearly 5 times as much",
            "Nearly 12 times as much",
            "Nearly 24 times as much"
        ],
        "correct": "Nearly 12 times as much",
         "explanation": "U.S. private AI investment reached $109.1 billion, which is nearly 12 times China's $9.3 billion[cite: 35, 881].",
        "topic": "Economy and Investment"
    },
    {
        "question": "What percentage of global organizations reported using AI in their business operations in 2024?",
        "options": [
            "39%",
            "55%",
            "78%",
            "90%"
        ],
        "correct": "78%",
         "explanation": "Business adoption of AI accelerated from 55% in 2023 to 78% in 2024[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "How many AI-enabled medical devices were approved by the FDA in 2023?",
        "options": [
            "6",
            "59",
            "122",
            "223"
        ],
        "correct": "223",
         "explanation": "The FDA approved 223 AI-enabled medical devices in 2023, up from only six in 2015[cite: 33, 879].",
        "topic": "Science and Medicine"
    },
    {
        "question": "Which country reported the highest level of AI optimism in 2024, with 83% of the public seeing benefits over harms?",
        "options": [
            "United States",
            "Canada",
            "China",
            "Germany"
        ],
        "correct": "China",
         "explanation": "China leads global AI optimism at 83%, whereas the U.S. and Canada remain at or below 40%[cite: 47, 48, 896].",
        "topic": "Public Opinion"
    },
    {
        "question": "What was the recorded carbon emission for training the Llama 3.1 405B model in 2024?",
        "options": [
            "588 tons",
            "1,200 tons",
            "5,184 tons",
            "8,930 tons"
        ],
        "correct": "8,930 tons",
         "explanation": "Llama 3.1 405B training emitted 8,930 tons of carbon, compared to 5,184 tons for GPT-4[cite: 118].",
        "topic": "Environmental Impact"
    },
    {
        "question": "According to the report, how often does the training compute for notable AI models currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 5 months",
         "explanation": "Training compute for notable AI models is now doubling approximately every five months[cite: 63, 106].",
        "topic": "Hardware and Compute"
    },
    {
        "question": "How many AI-related regulations were introduced by U.S. federal agencies in 2024?",
        "options": [
            "15",
            "25",
            "59",
            "122"
        ],
        "correct": "59",
         "explanation": "U.S. federal agencies more than doubled their AI-related regulations to 59 in 2024[cite: 54, 903].",
        "topic": "Policy and Governance"
    },
    {
        "question": "What is the primary barrier to computer science education in many African countries as noted in the report?",
        "options": [
            "Lack of student interest",
            "High cost of AI software",
            "Basic infrastructure gaps like electricity",
            "Government bans on AI"
        ],
        "correct": "Basic infrastructure gaps like electricity",
         "explanation": "Infrastructure gaps, specifically electricity, remain a major barrier to CS education in many African nations[cite: 59, 908].",
        "topic": "Education"
    },
    {
        "question": "The inference cost for a system performing at the GPT-3.5 level dropped by how much between 2022 and 2024?",
        "options": [
            "10-fold",
            "50-fold",
            "100-fold",
            "Over 280-fold"
        ],
        "correct": "Over 280-fold",
         "explanation": "Inference costs dropped from $20.00 to $0.07 per million tokens, representing a more than 280-fold reduction[cite: 50, 108].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which country leads in total AI patents, accounting for nearly 70% of all grants globally as of 2023?",
        "options": [
            "United States",
            "Japan",
            "China",
            "South Korea"
        ],
        "correct": "China",
         "explanation": "China leads in total AI patents, accounting for 69.7% of all grants as of 2023[cite: 113].",
        "topic": "Research and Development"
    },
    {
        "question": "Which 2024 model from OpenAI utilizes 'test-time compute' to significantly improve mathematical reasoning?",
        "options": [
            "GPT-4o",
            "o1",
            "SORA",
            "Veo 2"
        ],
        "correct": "o1",
         "explanation": "OpenAI's o1 model uses test-time compute to reason through outputs, scoring 74.4% on a math qualifying exam[cite: 133, 134].",
        "topic": "Technical Performance"
    },
    {
        "question": "By what annual rate is the power required for training notable AI models increasing?",
        "options": [
            "It is doubling annually",
            "It is increasing by 10% annually",
            "It is decreasing by 40% annually",
            "It is staying flat"
        ],
        "correct": "It is doubling annually",
         "explanation": "The power required for training notable AI models is doubling on an annual basis[cite: 63, 106].",
        "topic": "Hardware and Compute"
    },
    {
        "question": "On the 'FrontierMath' benchmark, what percentage of complex mathematics problems can top AI systems solve?",
        "options": [
            "2%",
            "10%",
            "35%",
            "74%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely difficult benchmark where AI systems currently solve only 2% of problems[cite: 138].",
        "topic": "Technical Performance"
    },
    {
        "question": "What was the growth in global private investment for Generative AI specifically in 2024?",
        "options": [
            "5.4%",
            "11.9%",
            "18.7%",
            "29.6%"
        ],
        "correct": "18.7%",
         "explanation": "Generative AI private investment grew by 18.7% globally in 2024, reaching $33.9 billion[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which 2024 scientific milestone reflected the recognition of AI's role in chemistry?",
        "options": [
            "Turing Award for reinforcement learning",
            "Nobel Prize for protein folding applications",
            "Nobel Prize for semiconductor development",
            "Fields Medal for AI-driven math proofs"
        ],
        "correct": "Nobel Prize for protein folding applications",
         "explanation": "A 2024 Nobel Prize in Chemistry recognized AI's application to protein folding[cite: 66, 919].",
        "topic": "Science and Medicine"
    }
,
    {
        "question": "What percentage of 'notable' AI models were produced by the industry sector in 2024?",
        "options": [
            "30%",
            "60%",
            "75%",
            "90%"
        ],
        "correct": "90%",
         "explanation": "Industry's lead in notable model development grew significantly from 60% in 2023 to nearly 90% in 2024[cite: 95].",
        "topic": "Research and Development"
    },
    {
        "question": "Which institutional sector has remained the leading producer of highly cited (top 100) AI publications for the last three years?",
        "options": [
            "Industry",
            "Government",
            "Academia",
            "Non-profit Research"
        ],
        "correct": "Academia",
         "explanation": "Despite industry's lead in model production, academia remains the top source of highly cited research publications[cite: 96].",
        "topic": "Research and Development"
    },
    {
        "question": "By what percentage point margin did AI performance on the SWE-bench improve between 2023 and 2024?",
        "options": [
            "18.8 points",
            "48.9 points",
            "67.3 points",
            "22.3 points"
        ],
        "correct": "67.3 points",
         "explanation": "AI performance on the software engineering benchmark SWE-bench saw a massive leap of 67.3 percentage points in just one year[cite: 76, 123].",
        "topic": "Technical Performance"
    },
    {
        "question": "Which 2024 model demonstrated a 142-fold reduction in size compared to 2022 models while maintaining similar performance on the MMLU benchmark?",
        "options": [
            "Llama 3.1 8B",
            "GPT-4o mini",
            "Phi-3 Mini",
            "Gemini 1.5 Flash"
        ],
        "correct": "Phi-3 Mini",
         "explanation": "Microsoft's Phi-3 Mini (3.8B parameters) achieved thresholds previously reached by models 142 times larger, like PaLM[cite: 142].",
        "topic": "Model Efficiency"
    },
    {
        "question": "By February 2025, what was the performance gap between the leading closed-weight and open-weight models on the Chatbot Arena Leaderboard?",
        "options": [
            "8.0%",
            "5.4%",
            "1.7%",
            "0.7%"
        ],
        "correct": "1.7%",
         "explanation": "The performance gap between top open and closed models narrowed from 8.0% in early 2024 to just 1.7% by early 2025[cite: 125, 126].",
        "topic": "Technical Performance"
    },
    {
        "question": "What was the total private AI investment in the United States in 2024?",
        "options": [
            "$4.5 billion",
            "$9.3 billion",
            "$33.9 billion",
            "$109.1 billion"
        ],
        "correct": "$109.1 billion",
         "explanation": "U.S. private AI investment reached $109.1 billion in 2024, nearly 12 times more than China[cite: 35, 881].",
        "topic": "Economy and Investment"
    },
    {
        "question": "How many AI-enabled medical devices were approved by the FDA in 2023?",
        "options": [
            "6",
            "59",
            "122",
            "223"
        ],
        "correct": "223",
         "explanation": "FDA approvals for AI-enabled medical devices rose to 223 in 2023, up from just six in 2015[cite: 33, 879].",
        "topic": "Science and Medicine"
    },
    {
        "question": "Which country reported the highest level of public AI optimism in 2024?",
        "options": [
            "United States",
            "Indonesia",
            "China",
            "Thailand"
        ],
        "correct": "China",
         "explanation": "China leads global AI optimism at 83%, compared to countries like the U.S. at 39%[cite: 47, 896].",
        "topic": "Public Opinion"
    },
    {
        "question": "What is the primary reason for limited access to computer science education in many African countries?",
        "options": [
            "Lack of student interest",
            "Governmental bans on AI",
            "Basic infrastructure gaps like electricity",
            "High cost of software licenses"
        ],
        "correct": "Basic infrastructure gaps like electricity",
         "explanation": "Despite curriculum progress, basic infrastructure like electricity remains a major barrier to education in Africa[cite: 59, 908].",
        "topic": "Education"
    },
    {
        "question": "In 2024, which country launched 'Project Transcendence,' a $100 billion AI infrastructure initiative?",
        "options": [
            "China",
            "Canada",
            "France",
            "Saudi Arabia"
        ],
        "correct": "Saudi Arabia",
         "explanation": "Saudi Arabia's Project Transcendence represents a massive $100 billion investment in national AI infrastructure[cite: 55, 904].",
        "topic": "Policy and Governance"
    },
    {
        "question": "The inference cost for a system performing at the GPT-3.5 level dropped by how much between 2022 and 2024?",
        "options": [
            "10-fold",
            "100-fold",
            "More than 280-fold",
            "900-fold"
        ],
        "correct": "More than 280-fold",
         "explanation": "Inference costs fell from $20.00 to $0.07 per million tokens, a more than 280-fold reduction[cite: 50, 108].",
        "topic": "Economy and Investment"
    },
    {
        "question": "According to the report, how often does the training compute for notable AI models currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 5 months",
         "explanation": "Training compute for notable AI models is now doubling approximately every five months[cite: 63, 106].",
        "topic": "Research and Development"
    },
    {
        "question": "What was the approximate carbon emission for training the Llama 3.1 405B model in 2024?",
        "options": [
            "588 tons",
            "5,184 tons",
            "8,930 tons",
            "12,000 tons"
        ],
        "correct": "8,930 tons",
         "explanation": "Training Llama 3.1 405B emitted 8,930 tons of carbon, significantly higher than previous models like GPT-4[cite: 118].",
        "topic": "Environmental Impact"
    },
    {
        "question": "Which new reasoning paradigm, involving models like OpenAI’s o1, allows AI to iteratively think through outputs?",
        "options": [
            "Zero-shot prompting",
            "Test-time compute",
            "Reinforcement learning from human feedback",
            "Few-shot learning"
        ],
        "correct": "Test-time compute",
         "explanation": "Models like o1 use test-time compute to iteratively reason, drastically improving math performance[cite: 132, 134].",
        "topic": "Technical Performance"
    },
    {
        "question": "How many AI-related regulations were introduced by U.S. federal agencies in 2024?",
        "options": [
            "25",
            "59",
            "109",
            "223"
        ],
        "correct": "59",
         "explanation": "U.S. federal agencies introduced 59 AI-related regulations in 2024, more than doubling the count from 2023[cite: 54, 903].",
        "topic": "Policy and Governance"
    },
    {
        "question": "What is the top AI system's performance on the rigorous 'Humanity's Last Exam' benchmark?",
        "options": [
            "2%",
            "8.80%",
            "35.50%",
            "71.70%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a difficult academic test where even the best system currently scores only 8.80%[cite: 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "As of 2024, what percentage of organizations reported using AI in their business?",
        "options": [
            "39%",
            "55%",
            "78%",
            "90%"
        ],
        "correct": "78%",
         "explanation": "Business adoption of AI increased from 55% in 2023 to 78% in 2024[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which country accounts for nearly 70% of all AI patent grants globally as of 2023?",
        "options": [
            "United States",
            "South Korea",
            "China",
            "Luxembourg"
        ],
        "correct": "China",
         "explanation": "China leads global AI patenting, accounting for 69.7% of all grants as of 2023[cite: 113].",
        "topic": "Research and Development"
    },
    {
        "question": "On the 'FrontierMath' benchmark, what percentage of complex problems can top AI systems solve?",
        "options": [
            "2%",
            "10%",
            "35%",
            "74%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely challenging benchmark where AI systems solve only 2% of problems[cite: 138].",
        "topic": "Technical Performance"
    },
    {
        "question": "Which 2024 scientific milestone recognized AI's contribution to protein folding?",
        "options": [
            "The Turing Award",
            "The Nobel Prize in Physics",
            "The Nobel Prize in Chemistry",
            "The Fields Medal"
        ],
        "correct": "The Nobel Prize in Chemistry",
         "explanation": "The Nobel Prize in Chemistry was awarded for work applying AI to protein folding[cite: 66, 919].",
        "topic": "Science and Medicine"
    }
,
    {
        "question": "Which specific AI-related concern saw the highest increase in public worry across G7 countries in 2024?",
        "options": [
            "Job loss to automation",
            "Lack of personal data privacy",
            "Deepfakes and misinformation",
            "Algorithmic bias in hiring"
        ],
        "correct": "Deepfakes and misinformation",
         "explanation": "The report highlights that misinformation and deepfakes are top concerns, particularly regarding their impact on global elections[cite: 23, 866].",
        "topic": "Responsible AI"
    },
    {
        "question": "In 2024, the United States federal government introduced how many AI-related regulations?",
        "options": [
            "25",
            "40",
            "59",
            "122"
        ],
        "correct": "59",
         "explanation": "U.S. federal agencies more than doubled their AI regulations to 59 in 2024, involving twice as many agencies as the previous year[cite: 54, 903].",
        "topic": "Policy and Governance"
    },
    {
        "question": "What was the percentage increase in AI legislative mentions across 75 countries between 2023 and 2024?",
        "options": [
            "5.4%",
            "11.9%",
            "21.3%",
            "41.8%"
        ],
        "correct": "21.3%",
         "explanation": "Legislative mentions of AI rose by 21.3% globally, marking a ninefold increase since 2016[cite: 55, 904].",
        "topic": "Policy and Governance"
    },
    {
        "question": "Which country launched a $100 billion national AI infrastructure initiative named 'Project Transcendence' in 2024?",
        "options": [
            "United States",
            "China",
            "Saudi Arabia",
            "France"
        ],
        "correct": "Saudi Arabia",
         "explanation": "Saudi Arabia's Project Transcendence is a massive $100 billion initiative aimed at expanding national AI infrastructure[cite: 55, 904].",
        "topic": "Policy and Governance"
    },
    {
        "question": "How many AI-enabled medical devices were approved by the FDA in 2023?",
        "options": [
            "6",
            "122",
            "223",
            "540"
        ],
        "correct": "223",
         "explanation": "The FDA approved 223 AI-enabled medical devices in 2023, showing a rapid increase from just six in 2015[cite: 33, 879].",
        "topic": "Science and Medicine"
    },
    {
        "question": "Which major scientific award in 2024 recognized the application of AI to protein folding?",
        "options": [
            "The Turing Award",
            "The Nobel Prize in Physics",
            "The Nobel Prize in Chemistry",
            "The Fields Medal"
        ],
        "correct": "The Nobel Prize in Chemistry",
         "explanation": "The 2024 Nobel Prize in Chemistry was awarded for work that applied deep learning to solve protein folding[cite: 66, 919].",
        "topic": "Science and Medicine"
    },
    {
        "question": "According to the report, what is the 'saturation' status of traditional AI benchmarks like MMLU and GSM8K?",
        "options": [
            "They are too difficult for current models",
            "They are becoming saturated as top models achieve near-perfect scores",
            "They are no longer used by industry",
            "They require too much compute to evaluate"
        ],
        "correct": "They are becoming saturated as top models achieve near-perfect scores",
         "explanation": "Traditional benchmarks are becoming saturated, leading to the creation of harder tests like 'Humanity's Last Exam'[cite: 136, 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "What is the recorded performance of AI systems on the 'FrontierMath' benchmark for complex mathematics?",
        "options": [
            "2%",
            "8.8%",
            "35.5%",
            "74.4%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely challenging benchmark where current AI systems solve only 2% of the problems[cite: 138].",
        "topic": "Technical Performance"
    },
    {
        "question": "By what factor did the inference cost for a GPT-3.5-level system drop between 2022 and 2024?",
        "options": [
            "10-fold",
            "50-fold",
            "100-fold",
            "Over 280-fold"
        ],
        "correct": "Over 280-fold",
         "explanation": "Costs fell from $20.00 to $0.07 per million tokens, representing a more than 280-fold reduction[cite: 108, 899].",
        "topic": "Economy and Investment"
    },
    {
        "question": "What percentage of global organizations reported adopting AI in their business operations in 2024?",
        "options": [
            "39%",
            "55%",
            "78%",
            "90%"
        ],
        "correct": "78%",
         "explanation": "Business adoption of AI accelerated significantly, rising from 55% in 2023 to 78% in 2024[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which country reported the highest level of AI optimism, with 83% of the public seeing more benefits than harm?",
        "options": [
            "United States",
            "Canada",
            "China",
            "Netherlands"
        ],
        "correct": "China",
         "explanation": "China leads global AI optimism at 83%, whereas optimism in the U.S. and Canada is around 40%[cite: 47, 48, 896].",
        "topic": "Public Opinion"
    },
    {
        "question": "The power required for training notable AI models is doubling at what frequency?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 12 months",
         "explanation": "While training compute doubles every five months, the actual power required for training doubles annually[cite: 106, 912].",
        "topic": "Hardware and Efficiency"
    },
    {
        "question": "How did the performance gap between top open-weight and closed-weight models change in early 2025?",
        "options": [
            "It widened to 15%",
            "It remained at 8%",
            "It narrowed to 1.7%",
            "It was eliminated (0%)"
        ],
        "correct": "It narrowed to 1.7%",
         "explanation": "The gap on the Chatbot Arena Leaderboard narrowed from 8.0% in early 2024 to just 1.7% by February 2025[cite: 51, 126].",
        "topic": "Research and Development"
    },
    {
        "question": "Which institutional sector produced nearly 90% of notable AI models in 2024?",
        "options": [
            "Academia",
            "Government",
            "Industry",
            "Non-profit"
        ],
        "correct": "Industry",
         "explanation": "Industry's lead in notable model development grew to nearly 90% in 2024, up from 60% the previous year[cite: 62, 911].",
        "topic": "Research and Development"
    },
    {
        "question": "What is the primary barrier to computer science education in many African countries according to the report?",
        "options": [
            "Lack of teaching staff",
            "Infrastructure gaps like electricity",
            "Student disinterest",
            "High software license costs"
        ],
        "correct": "Infrastructure gaps like electricity",
         "explanation": "Basic infrastructure gaps, specifically electricity, remain a significant barrier to education in several African nations[cite: 59, 908].",
        "topic": "Education"
    },
    {
        "question": "What score did the top AI system achieve on the 'Humanity's Last Exam' benchmark?",
        "options": [
            "2.00%",
            "8.80%",
            "35.50%",
            "71.70%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a rigorous test where the top system scores only 8.80%[cite: 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "In 2024, how many notable AI models did U.S.-based institutions produce compared to China?",
        "options": [
            "40 (U.S.) vs 15 (China)",
            "15 (U.S.) vs 40 (China)",
            "25 (U.S.) vs 25 (China)",
            "40 (U.S.) vs 3 (China)"
        ],
        "correct": "40 (U.S.) vs 15 (China)",
         "explanation": "U.S. institutions produced 40 notable models, significantly outperforming China's 15[cite: 39, 885].",
        "topic": "Global Trends"
    },
    {
        "question": "By 2024, what was the success rate of AI systems on the SWE-bench coding benchmark?",
        "options": [
            "4.4%",
            "18.8%",
            "48.9%",
            "71.7%"
        ],
        "correct": "71.7%",
         "explanation": "AI performance on SWE-bench jumped from 4.4% in 2023 to 71.7% in 2024[cite: 123].",
        "topic": "Technical Performance"
    },
    {
        "question": "What was the private AI investment in the United Kingdom in 2024?",
        "options": [
            "$109.1 billion",
            "$33.9 billion",
            "$9.3 billion",
            "$4.5 billion"
        ],
        "correct": "$4.5 billion",
         "explanation": "The UK recorded $4.5 billion in private AI investment, compared to $109.1 billion in the US[cite: 35, 881].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which training-related metric for LLMs is currently doubling every eight months?",
        "options": [
            "Training compute",
            "Dataset size",
            "Power requirements",
            "Inference cost"
        ],
        "correct": "Dataset size",
         "explanation": "Research indicates that dataset sizes for training LLMs are doubling every eight months[cite: 106, 912].",
        "topic": "Hardware and Efficiency"
    }
]