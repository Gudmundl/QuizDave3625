[
{
    "question": "Which institutional sector produced nearly 90% of notable AI models in 2024?",
    "options": [
"Academia",
"Government",
"Industry",
"Non-profit organizations"
    ],
    "correct": "Industry",
    "explanation": "Industry's lead in notable model development has grown significantly, accounting for nearly 90% of notable models in 2024 [1, 2].",
    "topic": "Industry Trends & Economics"
},
{
    "question": "What has happened to the cost of AI model inference (per million tokens) between 2022 and 2024?",
    "options": [
"It has increased due to higher compute needs.",
"It has remained stable.",
"It has dropped more than 280-fold.",
"It has halved every 12 months."
    ],
    "correct": "It has dropped more than 280-fold.",
    "explanation": "The cost of querying a model equivalent to GPT-3.5 dropped from $20.00 to $0.07 per million tokens in roughly 18 months [3, 4].",
    "topic": "Industry Trends & Economics"
},
{
    "question": "According to the AI Index 2025, which country leads in the total number of AI patents granted globally as of 2023?",
    "options": [
"United States",
"China",
"South Korea",
"Germany"
    ],
    "correct": "China",
    "explanation": "China leads in total AI patents, accounting for 69.7% of all grants globally in 2023 [5].",
    "topic": "Industry Trends & Economics"
},
{
    "question": "Which institutional producer remains the leader in highly cited (top 100) AI research publications?",
    "options": [
"Industry",
"Government",
"Academia",
"Independent Labs"
    ],
    "correct": "Academia",
    "explanation": "Despite industry's lead in model development, academia remains the leading institutional producer of highly cited publications [1, 2].",
    "topic": "Industry Trends & Economics"
},
{
    "question": "In 2024, scores on the coding benchmark SWE-bench jumped from 4.4% to what percentage?",
    "options": [
"25.5%",
"48.9%",
"71.7%",
"92.1%"
    ],
    "correct": "71.7%",
    "explanation": "AI systems' ability to solve coding problems on SWE-bench rose dramatically from 4.4% in 2023 to 71.7% in 2024 [6].",
    "topic": "Technical Benchmarking & Performance"
},
{
    "question": "What is the primary purpose of the MMMU benchmark introduced in 2023?",
    "options": [
"To measure pure text reasoning.",
"To test multimodal understanding and reasoning across disciplines.",
"To evaluate Python coding speed.",
"To measure hallucination rates in news summaries."
    ],
    "correct": "To test multimodal understanding and reasoning across disciplines.",
    "explanation": "MMMU is a massive multi-discipline multimodal understanding and reasoning benchmark designed for expert AGI evaluation [7-9].",
    "topic": "Technical Benchmarking & Performance"
},
{
    "question": "Which model released in late 2024 set a record on the ARC-AGI private holdout set with 87.5%?",
    "options": [
"GPT-4o",
"Claude 3.5 Sonnet",
"OpenAI o3",
"DeepSeek-V3"
    ],
    "correct": "OpenAI o3",
    "explanation": "OpenAI's o3 model set a new record of 87.5% on the ARC-AGI benchmark private holdout set [10].",
    "topic": "Technical Benchmarking & Performance"
},
{
    "question": "What does the 'Liar’s Dividend' refer to in the context of deepfake technology?",
    "options": [
"The profit made by creators of deepfake software.",
"The ability of individuals to deny genuine evidence by claiming it is fake.",
"The tax incentives for reporting misinformation.",
"The increased cost of training models on synthetic data."
    ],
    "correct": "The ability of individuals to deny genuine evidence by claiming it is fake.",
    "explanation": "The liar’s dividend is the phenomenon where deepfake technology allows people to dismiss real evidence, undermining accountability [11].",
    "topic": "Responsible AI, Fairness & Bias"
},
{
    "question": "Andrew Ng suggests that your development (dev) and test sets should ideally be:",
    "options": [
"Drawn from different distributions to test robustness.",
"Drawn from the same distribution.",
"At least 50% of your total data stock.",
"Labeled by different people to ensure diversity."
    ],
    "correct": "Drawn from the same distribution.",
    "explanation": "Choosing dev and test sets from the same distribution makes the team more efficient by ensuring they are optimizing for the final goal [12, 13].",
    "topic": "Machine Learning Strategy"
},
{
    "question": "In supervised learning, what is the 'single-number evaluation metric' used for?",
    "options": [
"To estimate the total cost of training.",
"To allow a team to quickly evaluate if one idea is better than another.",
"To determine the number of GPUs needed.",
"To count the number of restricted tokens in a dataset."
    ],
    "correct": "To allow a team to quickly evaluate if one idea is better than another.",
    "explanation": "A single-number metric, like classification accuracy, allows for rapid iteration by providing a clear comparison between models [14, 15].",
    "topic": "Machine Learning Strategy"
},
{
    "question": "What is 'Narrow AI' as defined in the course lectures?",
    "options": [
"AI that can perform any intellectual task a human can.",
"AI dedicated to assisting with or taking over specific tasks.",
"AI that has consciousness and emotions.",
"AI that only works on mobile devices."
    ],
    "correct": "AI dedicated to assisting with or taking over specific tasks.",
    "explanation": "Narrow AI is specialized for specific tasks, such as voice assistants or facial recognition [16, 17].",
    "topic": "AI Fundamentals & History"
},
{
    "question": "According to lecture slides, what percentage of an AI programmer's daily life is typically spent on data processing?",
    "options": [
"15%",
"50%",
"80%",
"95%"
    ],
    "correct": "80%",
    "explanation": "AI programmers spend the vast majority (80%) of their time cleaning, preparing, and labeling data [18, 19].",
    "topic": "Data Strategy & Training"
},
{
    "question": "Which of the following is a key reason for the rapid shrinkage of the 'data commons'?",
    "options": [
"Governments are deleting public websites.",
"Websites are using new protocols to curb data scraping for AI training.",
"AI models are deleting their own training data to save space.",
"Public internet usage is declining."
    ],
    "correct": "Websites are using new protocols to curb data scraping for AI training.",
    "explanation": "Data use restrictions increased as websites implemented protocols to prevent AI from scraping their content [20, 21].",
    "topic": "Data Strategy & Training"
},
{
    "question": "In the 'Benchmark Lifecycle,' what is the final stage before a benchmark is no longer used?",
    "options": [
"Implementation",
"Maintenance",
"Documentation",
"Retirement"
    ],
    "correct": "Retirement",
    "explanation": "The five stages of a benchmark lifecycle are Design, Implementation, Documentation, Maintenance, and Retirement [4, 22].",
    "topic": "Technical Benchmarking & Performance"
},
{
    "question": "Which type of learning involves an agent learning by trial and error through rewards and penalties?",
    "options": [
"Supervised learning",
"Unsupervised learning",
"Reinforcement learning",
"Symbolic AI"
    ],
    "correct": "Reinforcement learning",
    "explanation": "Reinforcement learning enables an agent to learn through feedback (rewards or penalties) based on its own actions [23, 24].",
    "topic": "Machine Learning Types & Algorithms"
},
{
    "question": "The 'HHEM' leaderboard is specifically designed to evaluate what in AI models?",
    "options": [
"Mathematical reasoning",
"Hallucination rates",
"Coding speed",
"Visual common sense"
    ],
    "correct": "Hallucination rates",
    "explanation": "The Hughes Hallucination Evaluation Model (HHEM) measures how often models generate factually incorrect or 'hallucinated' outputs [25, 26].",
    "topic": "Responsible AI, Fairness & Bias"
},
{
    "question": "What is the 'Foundation Model Transparency Index' (FMTI) used for?",
    "options": [
"To measure how fast a model can process data.",
"To track transparency in data sources, labor, and development choices.",
"To rank models by their public market value.",
"To calculate the energy efficiency of GPUs."
    ],
    "correct": "To track transparency in data sources, labor, and development choices.",
    "explanation": "The FMTI tracks transparency across Indicators such as data access, labor disclosures, and algorithmic choices [27, 28].",
    "topic": "Transparency, Explainability & Security"
},
{
    "question": "Which model variant holds the highest grounding score on the FACTS benchmark as of the AI Index 2025 report?",
    "options": [
"gpt-4o",
"claude-3.5-sonnet",
"gemini-2.0-flash-exp",
"o1-preview"
    ],
    "correct": "gemini-2.0-flash-exp",
    "explanation": "Currently, Gemini-2.0-Flash-Exp holds the highest grounding score (83.6%) on the FACTS factuality benchmark [26].",
    "topic": "Technical Benchmarking & Performance"
},
{
    "question": "Which benchmark is specifically focused on evaluating language agents on GitHub issues?",
    "options": [
"MMLU",
"GPQA Diamond",
"SWE-bench",
"HumanEval"
    ],
    "correct": "SWE-bench",
    "explanation": "SWE-bench evaluates the ability of language models to resolve real-world software engineering issues on GitHub [7, 29].",
    "topic": "Technical Benchmarking & Performance"
},
{
    "question": "What significant trend was noted regarding Chinese LLMs in the AI Index 2025?",
    "options": [
"They have stopped using the MMLU benchmark.",
"They are rapidly improving and converging with top-tier Western models.",
"They are focused solely on image generation.",
"They are significantly more expensive to run than US models."
    ],
    "correct": "They are rapidly improving and converging with top-tier Western models.",
    "explanation": "The report highlights the improving quality and converging performance of Chinese LLMs compared to global frontier models [4, 30].",
    "topic": "Industry Trends & Economics"
},
{
    "question": "According to lecture materials, when is Machine Learning NOT recommended?",
    "options": [
"When rules are too complex for manual coding.",
"When the problem is simple and can be solved with traditional programming.",
"When data is constantly changing.",
"When hand-written rules plateau in performance."
    ],
    "correct": "When the problem is simple and can be solved with traditional programming.",
    "explanation": "Machine learning should be used when rules are complex or data is high-dimensional; simple problems are better suited for conventional programming [31, 32].",
    "topic": "Data Strategy & Training"
},
{
    "question": "What does the 'LMSYS Chatbot Arena' use to rank AI models?",
    "options": [
"Automated Python scripts.",
"Human preference through side-by-side chat evaluations.",
"The number of GPUs used during training.",
"The file size of the model weights."
    ],
    "correct": "Human preference through side-by-side chat evaluations.",
    "explanation": "Chatbot Arena is an open platform where humans interact with and rank models based on their preferences [33, 34].",
    "topic": "Technical Benchmarking & Performance"
},
{
    "question": "What is 'Implicit Bias' in LLMs as described in Chapter 3 of the AI Index?",
    "options": [
"Biases that models explicitly state in their terms of service.",
"Biases that occur despite measures taken to curb explicit ones.",
"Biases that only appear in non-English languages.",
"Biases that are intentionally programmed for security reasons."
    ],
    "correct": "Biases that occur despite measures taken to curb explicit ones.",
    "explanation": "Even models designed to be explicitly unbiased continue to exhibit subtle, systemic implicit biases in decision-making [35, 36].",
    "topic": "Responsible AI, Fairness & Bias"
},
{
    "question": "In the United States, which category saw the sharpest rise in AI-related state-level laws passed in 2024?",
    "options": [
"Autonomous driving regulations",
"Deepfakes in intimate imagery and elections",
"Healthcare privacy laws",
"Financial algorithmic auditing"
    ],
    "correct": "Deepfakes in intimate imagery and elections",
    "explanation": "There was a massive spike in 2024 for laws enacted regarding AI-generated deepfakes in both imagery and elections [37].",
    "topic": "Politics, Policy & Society"
},
{
    "question": "Which machine learning method is best suited for identifying groups/patterns in unlabeled data?",
    "options": [
"Classification",
"Regression",
"Clustering",
"Supervised Learning"
    ],
    "correct": "Clustering",
    "explanation": "Clustering is an unsupervised learning task where the goal is to discover groupings within unlabeled data [38, 39].",
    "topic": "Machine Learning Types & Algorithms"
},
{
    "question": "What is the 'Satisficing Metric' as defined by Andrew Ng?",
    "options": [
"The metric you want to maximize as much as possible.",
"A metric that must meet a certain threshold but doesn't need to be maximized.",
"A metric that measures how satisfied the human programmers are.",
"A metric used only in reinforcement learning."
    ],
    "correct": "A metric that must meet a certain threshold but doesn't need to be maximized.",
    "explanation": "A satisficing metric defines a 'good enough' threshold, while an optimizing metric is the one you try to maximize [40].",
    "topic": "Machine Learning Strategy"
},
{
    "question": "According to the AI Index, how has AI impacted scientific discoveries like protein folding?",
    "options": [
"It has slowed down discovery due to inference costs.",
"It led to Nobel Prizes in Physics and Chemistry.",
"It has replaced all laboratory experiments.",
"It has only been useful for educational purposes."
    ],
    "correct": "It led to Nobel Prizes in Physics and Chemistry.",
    "explanation": "AI's impact on science was recognized in 2024 with Nobel Prizes for deep learning and protein folding applications [41, 42].",
    "topic": "AI Consequences & Science"
},
{
    "question": "What is the primary obstacle organizations face when trying to implement responsible AI measures?",
    "options": [
"Lack of interest from stakeholders.",
"Knowledge and training gaps.",
"The cost of cloud electricity.",
"The weight of the models."
    ],
    "correct": "Knowledge and training gaps.",
    "explanation": "In a McKinsey survey, 51% of respondents cited knowledge and training gaps as the main obstacle to RAI measures [43].",
    "topic": "Responsible AI, Fairness & Bias"
},
{
    "question": "In the context of technical performance, what is 'Inference-Time Compute'?",
    "options": [
"The amount of data used to train the model.",
"Compute used during the actual generation of an answer (e.g., in o1 models).",
"The total electricity used by the data center.",
"The speed at which human experts can verify an answer."
    ],
    "correct": "Compute used during the actual generation of an answer (e.g., in o1 models).",
    "explanation": "OpenAI's o1 and o3 models focus on increasing compute during the 'thinking' phase of generating a response [10, 33].",
    "topic": "Model Training & Optimization"
},
{
    "question": "Which benchmark evaluates AI performance on PhD-level science questions?",
    "options": [
"MMLU",
"GPQA Diamond",
"GSM8K",
"SQuAD 2.0"
    ],
    "correct": "GPQA Diamond",
    "explanation": "GPQA is a Google-proof Q&A benchmark featuring difficult PhD-level science questions [44, 45].",
    "topic": "Technical Benchmarking & Performance"
}

]