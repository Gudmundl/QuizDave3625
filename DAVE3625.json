[
    {
        "question": "Which institutional sector produced nearly 90% of notable AI models in 2024?",
        "options": [
            "Academia",
            "Government",
            "Industry",
            "Non-profit organizations"
        ],
        "correct": "Industry",
         "explanation": "Industry's lead in notable model development grew significantly, rising from 60% in 2023 to nearly 90% in 2024[cite: 62, 95].",
        "topic": "Research and Development Trends"
    },
    {
        "question": "Which country produced the highest total of AI publications and citations in 2023?",
        "options": [
            "United States",
            "China",
            "United Kingdom",
            "India"
        ],
        "correct": "China",
         "explanation": "China led the world in AI publication volume (23.2%) and citations (22.6%) in 2023[cite: 98].",
        "topic": "Research and Development Trends"
    },
    {
        "question": "How did the performance gap between top open-weight and closed-weight models change between January 2024 and February 2025?",
        "options": [
            "It increased from 1.7% to 8.0%",
            "It stayed constant at 5.4%",
            "It narrowed from 8.0% to 1.7%",
            "It disappeared entirely (0%)"
        ],
        "correct": "It narrowed from 8.0% to 1.7%",
         "explanation": "Leading open-weight models have rapidly caught up to closed-weight counterparts on the Chatbot Arena Leaderboard[cite: 125, 126].",
        "topic": "Technical Performance"
    },
    {
        "question": "What was the percentage-point increase in AI performance on the SWE-bench between 2023 and 2024?",
        "options": [
            "18.8 points",
            "48.9 points",
            "67.3 points",
            "22.3 points"
        ],
        "correct": "67.3 points",
         "explanation": "AI performance on the software engineering benchmark SWE-bench saw a massive leap of 67.3 percentage points in just one year[cite: 30, 876].",
        "topic": "Technical Performance"
    },
    {
        "question": "Which new reasoning paradigm was introduced in 2024 to improve AI performance on complex mathematical tasks?",
        "options": [
            "Reinforcement learning from human feedback",
            "Test-time compute",
            "Zero-shot prompting",
            "Low-rank adaptation"
        ],
        "correct": "Test-time compute",
         "explanation": "Models like OpenAI’s o1 use test-time compute to iteratively reason through outputs, significantly boosting math performance[cite: 132, 133].",
        "topic": "Technical Performance"
    },
    {
        "question": "In 2024, how much private AI investment did the United States record compared to China?",
        "options": [
            "Nearly 2 times as much",
            "Nearly 5 times as much",
            "Nearly 12 times as much",
            "Nearly 24 times as much"
        ],
        "correct": "Nearly 12 times as much",
         "explanation": "U.S. private AI investment reached $109.1 billion, which is nearly 12 times China's $9.3 billion[cite: 35, 881].",
        "topic": "Economy and Investment"
    },
    {
        "question": "What percentage of organizations reported using AI in 2024?",
        "options": [
            "40%",
            "55%",
            "78%",
            "90%"
        ],
        "correct": "78%",
         "explanation": "Business adoption of AI accelerated from 55% in 2023 to 78% in 2024[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "The inference cost for a system performing at the GPT-3.5 level dropped by how much between 2022 and 2024?",
        "options": [
            "10-fold",
            "50-fold",
            "150-fold",
            "Over 280-fold"
        ],
        "correct": "Over 280-fold",
         "explanation": "Costs dropped from $20.00 to $0.07 per million tokens, representing a more than 280-fold reduction[cite: 50, 108].",
        "topic": "AI Hardware and Efficiency"
    },
    {
        "question": "How often does the training compute for notable AI models currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 2 years"
        ],
        "correct": "Every 5 months",
         "explanation": "New research indicates that training compute requirements are doubling approximately every five months[cite: 63, 106].",
        "topic": "AI Hardware and Efficiency"
    },
    {
        "question": "Which country reported the highest level of AI optimism in 2024, with 83% seeing AI as more beneficial than harmful?",
        "options": [
            "United States",
            "Canada",
            "China",
            "Germany"
        ],
        "correct": "China",
         "explanation": "China leads global AI optimism at 83%, whereas countries like the U.S. and Canada remain below 40%[cite: 47, 48, 896].",
        "topic": "Public Opinion"
    },
    {
        "question": "In 2023, how many AI-enabled medical devices were approved by the FDA?",
        "options": [
            "6",
            "59",
            "150",
            "223"
        ],
        "correct": "223",
         "explanation": "The FDA approved 223 AI-enabled medical devices in 2023, a massive increase from only six in 2015[cite: 33, 879].",
        "topic": "Science and Medicine"
    },
    {
        "question": "Which 2024 AI model had the highest recorded carbon emissions during training at 8,930 tons?",
        "options": [
            "GPT-3",
            "GPT-4",
            "Llama 3.1 405B",
            "Gemini 1.5 Flash"
        ],
        "correct": "Llama 3.1 405B",
         "explanation": "Llama 3.1 405B training emitted 8,930 tons of carbon, compared to 5,184 tons for GPT-4[cite: 118].",
        "topic": "AI Hardware and Efficiency"
    },
    {
        "question": "What is the primary reason many African countries face limited access to computer science education?",
        "options": [
            "Lack of interest from students",
            "Government bans on AI",
            "Basic infrastructure gaps like electricity",
            "High cost of software licenses"
        ],
        "correct": "Basic infrastructure gaps like electricity",
         "explanation": "Despite progress in curriculum planning, basic infrastructure like electricity remains a barrier in many African nations[cite: 59, 908].",
        "topic": "Education"
    },
    {
        "question": "How many AI-related regulations were introduced by U.S. federal agencies in 2024?",
        "options": [
            "15",
            "25",
            "59",
            "122"
        ],
        "correct": "59",
         "explanation": "U.S. federal agencies more than doubled their AI-related regulations to 59 in 2024[cite: 54, 903].",
        "topic": "Policy and Governance"
    },
    {
        "question": "On which rigorous academic benchmark does the top AI system currently score only 8.80%?",
        "options": [
            "MMLU",
            "GPQA",
            "Humanity's Last Exam",
            "FrontierMath"
        ],
        "correct": "Humanity's Last Exam",
         "explanation": "Humanity's Last Exam is a rigorous test where even the best AI systems currently struggle, scoring under 9%[cite: 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "Which organization's robotaxi fleet provides over 150,000 autonomous rides each week in the U.S.?",
        "options": [
            "Baidu",
            "Tesla",
            "Waymo",
            "Uber"
        ],
        "correct": "Waymo",
         "explanation": "Waymo is cited as a large U.S. operator providing over 150,000 autonomous rides weekly[cite: 33, 879].",
        "topic": "Everyday AI Integration"
    },
    {
        "question": "What was the growth rate of AI patenting between 2022 and 2023?",
        "options": [
            "5.4%",
            "18.7%",
            "21.3%",
            "29.6%"
        ],
        "correct": "29.6%",
         "explanation": "AI patents grew significantly by 29.6% in a single year as of 2023[cite: 112].",
        "topic": "Research and Development Trends"
    },
    {
        "question": "Which country leads in AI patents per capita according to the 2025 report?",
        "options": [
            "China",
            "United States",
            "South Korea",
            "Japan"
        ],
        "correct": "South Korea",
         "explanation": "While China leads in total patents, South Korea and Luxembourg are top producers on a per capita basis[cite: 113].",
        "topic": "Research and Development Trends"
    },
    {
        "question": "According to the report, what is the 'saturation' issue in AI benchmarking?",
        "options": [
            "Models are becoming too large to run benchmarks",
            "Traditional benchmarks like MMLU are becoming too easy for top models",
            "Benchmarks are too expensive to administer",
            "There is not enough data to create new benchmarks"
        ],
        "correct": "Traditional benchmarks like MMLU are becoming too easy for top models",
         "explanation": "The saturation of traditional benchmarks has pushed researchers to develop more challenging evaluations like FrontierMath[cite: 136].",
        "topic": "Technical Performance"
    },
    {
        "question": "What is the primary challenge for AI models in 'high-stakes' settings as noted in the report?",
        "options": [
            "High energy consumption",
            "Lack of data",
            "Failure to reliably solve logic tasks even with provably correct solutions",
            "Slow processing speeds"
        ],
        "correct": "Failure to reliably solve logic tasks even with provably correct solutions",
         "explanation": "AI models still struggle with complex reasoning benchmarks like PlanBench, limiting their use where precision is critical[cite: 68, 921].",
        "topic": "Responsible AI"
    },

    {
        "question": "What percentage of computer science publications were AI-related in 2023?",
        "options": [
            "10.2%",
            "21.6%",
            "35.4%",
            "41.8%"
        ],
        "correct": "41.8%",
         "explanation": "AI's share of computer science publications grew from 21.6% in 2013 to 41.8% in 2023[cite: 102].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "Which institutional sector has remained the leading producer of the 'top 100' highly cited AI publications over the last three years?",
        "options": [
            "Industry",
            "Government",
            "Academia",
            "Non-profit Research"
        ],
        "correct": "Academia",
         "explanation": "While industry leads in model development, academia is the top producer of highly influential (top 100) research[cite: 96].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "By what factor did AI publication totals grow between 2013 and 2023?",
        "options": [
            "Nearly doubled",
            "Nearly tripled",
            "Exactly quadrupled",
            "Tenfold increase"
        ],
        "correct": "Nearly tripled",
         "explanation": "Total AI publications increased from approximately 102,000 in 2013 to over 242,000 in 2023[cite: 101].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "In 2024, how many notable AI models were produced by European institutions compared to the United States?",
        "options": [
            "3 models vs 40 models",
            "15 models vs 40 models",
            "10 models vs 25 models",
            "3 models vs 15 models"
        ],
        "correct": "3 models vs 40 models",
         "explanation": "U.S.-based institutions produced 40 notable models, significantly surpassing Europe's total of three[cite: 103].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "What was the performance gap between U.S. and Chinese models on the HumanEval benchmark at the end of 2024?",
        "options": [
            "31.6 percentage points",
            "17.5 percentage points",
            "3.7 percentage points",
            "0.3 percentage points"
        ],
        "correct": "3.7 percentage points",
         "explanation": "The gap on HumanEval narrowed from 31.6 points in 2023 to just 3.7 points by the end of 2024[cite: 128, 129].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "Which country accounts for nearly 70% of all AI patent grants as of 2023?",
        "options": [
            "United States",
            "Japan",
            "China",
            "South Korea"
        ],
        "correct": "China",
         "explanation": "China leads in total AI patents, accounting for 69.7% of all grants globally[cite: 113].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "According to the report, which country stands out as a top AI patent producer on a 'per capita' basis?",
        "options": [
            "China",
            "India",
            "Luxembourg",
            "Brazil"
        ],
        "correct": "Luxembourg",
         "explanation": "While China leads in totals, South Korea and Luxembourg are top producers on a per capita basis[cite: 113].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "How many AI-enabled medical devices did the FDA approve in 2015 compared to 2023?",
        "options": [
            "6 in 2015 vs 223 in 2023",
            "50 in 2015 vs 150 in 2023",
            "0 in 2015 vs 100 in 2023",
            "12 in 2015 vs 88 in 2023"
        ],
        "correct": "6 in 2015 vs 223 in 2023",
         "explanation": "FDA approvals for AI medical devices rose from just six in 2015 to 223 in 2023[cite: 33].",
        "topic": "AI in Medicine and Science"
    },
    {
        "question": "Which 2024 scientific milestone reflected AI's impact on chemistry?",
        "options": [
            "The Turing Award for deep learning",
            "A Nobel Prize for protein folding applications",
            "The Fields Medal for AI-driven proofs",
            "A Nobel Prize for reinforcement learning"
        ],
        "correct": "A Nobel Prize for protein folding applications",
         "explanation": "A 2024 Nobel Prize in Chemistry recognized AI's application to protein folding[cite: 66].",
        "topic": "AI in Medicine and Science"
    },
    {
        "question": "What is the recorded performance of top AI systems on the 'FrontierMath' benchmark?",
        "options": [
            "90%",
            "50%",
            "8.8%",
            "2%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely difficult benchmark where current AI systems solve only 2% of problems[cite: 138].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "On the 'BigCodeBench' coding benchmark, what is the human standard for success compared to the current top AI performance?",
        "options": [
            "97% (Human) vs 35.5% (AI)",
            "100% (Human) vs 71.7% (AI)",
            "80% (Human) vs 50% (AI)",
            "95% (Human) vs 15% (AI)"
        ],
        "correct": "97% (Human) vs 35.5% (AI)",
         "explanation": "AI systems currently achieve a 35.5% success rate on BigCodeBench, far below the 97% human standard[cite: 139].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "The 'Humanity's Last Exam' benchmark is characterized by which top system score?",
        "options": [
            "74.4%",
            "48.9%",
            "18.8%",
            "8.80%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a rigorous test where the top AI system currently scores just 8.80%[cite: 137].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "By what factor did the cost of querying a GPT-3.5-level system drop between late 2022 and late 2024?",
         "explanation": "The cost dropped from $20.00 to $0.07 per million tokens, a more than 280-fold reduction[cite: 108].",
        "options": [
            "10-fold",
            "100-fold",
            "More than 280-fold",
            "Exactly 500-fold"
        ],
        "correct": "More than 280-fold",
        "topic": "Inference and Operational Costs"
    },
    {
        "question": "What is the typical range of annual price performance improvement for machine learning hardware?",
        "options": [
            "10%",
            "30%",
            "50%",
            "75%"
        ],
        "correct": "30%",
         "explanation": "Hardware price performance has improved with costs dropping by 30% per year[cite: 116].",
        "topic": "AI Hardware and Energy"
    },
    {
        "question": "According to the 2025 report, how often do dataset sizes for training Large Language Models (LLMs) currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 8 months",
         "explanation": "Research indicates that training dataset sizes for LLMs double every eight months[cite: 106].",
        "topic": "Training Data and Compute"
    },
    {
        "question": "The power required for training notable AI models is increasing at what annual rate?",
        "options": [
            "It is doubling annually",
            "It is decreasing by 40% annually",
            "It is staying flat due to efficiency",
            "It is increasing by 10% annually"
        ],
        "correct": "It is doubling annually",
         "explanation": "The report notes that power required for training is doubling on an annual basis[cite: 106].",
        "topic": "AI Hardware and Energy"
    },
    {
        "question": "Which specific 2024 model released by OpenAI utilizes 'test-time compute' to improve math performance?",
        "options": [
            "GPT-4o",
            "o1",
            "SORA",
            "DALL-E 3"
        ],
        "correct": "o1",
         "explanation": "OpenAI's o1 model uses test-time compute to reason through outputs, significantly outperforming GPT-4o on math exams[cite: 133, 134].",
        "topic": "Technical Innovation"
    },
    {
        "question": "Compared to GPT-4o, how much slower is the o1 model due to its reasoning process?",
        "options": [
            "2 times slower",
            "5 times slower",
            "10 times slower",
            "30 times slower"
        ],
        "correct": "30 times slower",
         "explanation": "While more capable at reasoning, the o1 model is approximately 30 times slower than GPT-4o[cite: 135].",
        "topic": "Technical Innovation"
    },
    {
        "question": "What was the private AI investment in the United Kingdom in 2024?",
        "options": [
            "$109.1 billion",
            "$33.9 billion",
            "$9.3 billion",
            "$4.5 billion"
        ],
        "correct": "$4.5 billion",
         "explanation": "The U.K. recorded $4.5 billion in private AI investment, which is 24 times less than the U.S. total[cite: 35].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Global private investment in 'Generative AI' specifically reached what amount in 2024?",
        "options": [
            "$10.5 billion",
            "$33.9 billion",
            "$109.1 billion",
            "$200 billion"
        ],
        "correct": "$33.9 billion",
         "explanation": "Generative AI attracted $33.9 billion globally in private investment, an 18.7% increase from the previous year[cite: 36].",
        "topic": "Economy and Investment"
    },
    
    {
        "question": "What percentage of computer science publications were AI-related in 2023?",
        "options": [
            "10.2%",
            "21.6%",
            "35.4%",
            "41.8%"
        ],
        "correct": "41.8%",
         "explanation": "AI's share of computer science publications grew from 21.6% in 2013 to 41.8% in 2023[cite: 102].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "Which institutional sector has remained the leading producer of the 'top 100' highly cited AI publications over the last three years?",
        "options": [
            "Industry",
            "Government",
            "Academia",
            "Non-profit Research"
        ],
        "correct": "Academia",
         "explanation": "While industry leads in model development, academia is the top producer of highly influential (top 100) research[cite: 96].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "By what factor did AI publication totals grow between 2013 and 2023?",
        "options": [
            "Nearly doubled",
            "Nearly tripled",
            "Exactly quadrupled",
            "Tenfold increase"
        ],
        "correct": "Nearly tripled",
         "explanation": "Total AI publications increased from approximately 102,000 in 2013 to over 242,000 in 2023[cite: 101].",
        "topic": "Academic Research Trends"
    },
    {
        "question": "In 2024, how many notable AI models were produced by European institutions compared to the United States?",
        "options": [
            "3 models vs 40 models",
            "15 models vs 40 models",
            "10 models vs 25 models",
            "3 models vs 15 models"
        ],
        "correct": "3 models vs 40 models",
         "explanation": "U.S.-based institutions produced 40 notable models, significantly surpassing Europe's total of three[cite: 103].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "What was the performance gap between U.S. and Chinese models on the HumanEval benchmark at the end of 2024?",
        "options": [
            "31.6 percentage points",
            "17.5 percentage points",
            "3.7 percentage points",
            "0.3 percentage points"
        ],
        "correct": "3.7 percentage points",
         "explanation": "The gap on HumanEval narrowed from 31.6 points in 2023 to just 3.7 points by the end of 2024[cite: 128, 129].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "Which country accounts for nearly 70% of all AI patent grants as of 2023?",
        "options": [
            "United States",
            "Japan",
            "China",
            "South Korea"
        ],
        "correct": "China",
         "explanation": "China leads in total AI patents, accounting for 69.7% of all grants globally[cite: 113].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "According to the report, which country stands out as a top AI patent producer on a 'per capita' basis?",
        "options": [
            "China",
            "India",
            "Luxembourg",
            "Brazil"
        ],
        "correct": "Luxembourg",
         "explanation": "While China leads in totals, South Korea and Luxembourg are top producers on a per capita basis[cite: 113].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "How many AI-enabled medical devices did the FDA approve in 2015 compared to 2023?",
        "options": [
            "6 in 2015 vs 223 in 2023",
            "50 in 2015 vs 150 in 2023",
            "0 in 2015 vs 100 in 2023",
            "12 in 2015 vs 88 in 2023"
        ],
        "correct": "6 in 2015 vs 223 in 2023",
         "explanation": "FDA approvals for AI medical devices rose from just six in 2015 to 223 in 2023[cite: 33].",
        "topic": "AI in Medicine and Science"
    },
    {
        "question": "Which 2024 scientific milestone reflected AI's impact on chemistry?",
        "options": [
            "The Turing Award for deep learning",
            "A Nobel Prize for protein folding applications",
            "The Fields Medal for AI-driven proofs",
            "A Nobel Prize for reinforcement learning"
        ],
        "correct": "A Nobel Prize for protein folding applications",
         "explanation": "A 2024 Nobel Prize in Chemistry recognized AI's application to protein folding[cite: 66].",
        "topic": "AI in Medicine and Science"
    },
    {
        "question": "What is the recorded performance of top AI systems on the 'FrontierMath' benchmark?",
        "options": [
            "90%",
            "50%",
            "8.8%",
            "2%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely difficult benchmark where current AI systems solve only 2% of problems[cite: 138].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "On the 'BigCodeBench' coding benchmark, what is the human standard for success compared to the current top AI performance?",
        "options": [
            "97% (Human) vs 35.5% (AI)",
            "100% (Human) vs 71.7% (AI)",
            "80% (Human) vs 50% (AI)",
            "95% (Human) vs 15% (AI)"
        ],
        "correct": "97% (Human) vs 35.5% (AI)",
         "explanation": "AI systems currently achieve a 35.5% success rate on BigCodeBench, far below the 97% human standard[cite: 139].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "The 'Humanity's Last Exam' benchmark is characterized by which top system score?",
        "options": [
            "74.4%",
            "48.9%",
            "18.8%",
            "8.80%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a rigorous test where the top AI system currently scores just 8.80%[cite: 137].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "By what factor did the cost of querying a GPT-3.5-level system drop between late 2022 and late 2024?",
         "explanation": "The cost dropped from $20.00 to $0.07 per million tokens, a more than 280-fold reduction[cite: 108].",
        "options": [
            "10-fold",
            "100-fold",
            "More than 280-fold",
            "Exactly 500-fold"
        ],
        "correct": "More than 280-fold",
        "topic": "Inference and Operational Costs"
    },
    {
        "question": "What is the typical range of annual price performance improvement for machine learning hardware?",
        "options": [
            "10%",
            "30%",
            "50%",
            "75%"
        ],
        "correct": "30%",
         "explanation": "Hardware price performance has improved with costs dropping by 30% per year[cite: 116].",
        "topic": "AI Hardware and Energy"
    },
    {
        "question": "According to the 2025 report, how often do dataset sizes for training Large Language Models (LLMs) currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 8 months",
         "explanation": "Research indicates that training dataset sizes for LLMs double every eight months[cite: 106].",
        "topic": "Training Data and Compute"
    },
    {
        "question": "The power required for training notable AI models is increasing at what annual rate?",
        "options": [
            "It is doubling annually",
            "It is decreasing by 40% annually",
            "It is staying flat due to efficiency",
            "It is increasing by 10% annually"
        ],
        "correct": "It is doubling annually",
         "explanation": "The report notes that power required for training is doubling on an annual basis[cite: 106].",
        "topic": "AI Hardware and Energy"
    },
    {
        "question": "Which specific 2024 model released by OpenAI utilizes 'test-time compute' to improve math performance?",
        "options": [
            "GPT-4o",
            "o1",
            "SORA",
            "DALL-E 3"
        ],
        "correct": "o1",
         "explanation": "OpenAI's o1 model uses test-time compute to reason through outputs, significantly outperforming GPT-4o on math exams[cite: 133, 134].",
        "topic": "Technical Innovation"
    },
    {
        "question": "Compared to GPT-4o, how much slower is the o1 model due to its reasoning process?",
        "options": [
            "2 times slower",
            "5 times slower",
            "10 times slower",
            "30 times slower"
        ],
        "correct": "30 times slower",
         "explanation": "While more capable at reasoning, the o1 model is approximately 30 times slower than GPT-4o[cite: 135].",
        "topic": "Technical Innovation"
    },
    {
        "question": "What was the private AI investment in the United Kingdom in 2024?",
        "options": [
            "$109.1 billion",
            "$33.9 billion",
            "$9.3 billion",
            "$4.5 billion"
        ],
        "correct": "$4.5 billion",
         "explanation": "The U.K. recorded $4.5 billion in private AI investment, which is 24 times less than the U.S. total[cite: 35].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Global private investment in 'Generative AI' specifically reached what amount in 2024?",
        "options": [
            "$10.5 billion",
            "$33.9 billion",
            "$109.1 billion",
            "$200 billion"
        ],
        "correct": "$33.9 billion",
         "explanation": "Generative AI attracted $33.9 billion globally in private investment, an 18.7% increase from the previous year[cite: 36].",
        "topic": "Economy and Investment"
    }
,
    {
        "question": "What percentage of 'notable' AI models in 2024 were produced by the industry sector?",
        "options": [
            "30%",
            "60%",
            "75%",
            "90%"
        ],
        "correct": "90%",
         "explanation": "Industry's lead in notable model development grew significantly from 60% in 2023 to nearly 90% in 2024[cite: 62, 95].",
        "topic": "Research and Development"
    },
    {
        "question": "According to the 2025 report, which sector remains the top producer of highly cited (top 100) AI research papers?",
        "options": [
            "Industry",
            "Government",
            "Academia",
            "Non-profit Organizations"
        ],
        "correct": "Academia",
         "explanation": "While industry leads in model development, academia has remained the leading producer of highly cited publications over the past three years[cite: 62, 96].",
        "topic": "Research and Development"
    },
    {
        "question": "By how many percentage points did AI performance on the software engineering benchmark 'SWE-bench' increase between 2023 and 2024?",
        "options": [
            "18.8 points",
            "48.9 points",
            "67.3 points",
            "8.8 points"
        ],
        "correct": "67.3 points",
         "explanation": "AI performance on the SWE-bench saw a massive leap of 67.3 percentage points in just one year[cite: 30, 876].",
        "topic": "Technical Performance"
    },
    {
        "question": "What is the top AI system's current score on the rigorous 'Humanity's Last Exam' benchmark?",
        "options": [
            "2.00%",
            "8.80%",
            "35.50%",
            "74.40%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a rigorous academic test where the top AI system currently scores only 8.80%[cite: 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "How did the performance gap between top open-weight and closed-weight models change from January 2024 to February 2025?",
        "options": [
            "It widened from 1.7% to 8.0%",
            "It narrowed from 8.0% to 1.7%",
            "It remained constant at 5.4%",
            "It disappeared entirely (0%)"
        ],
        "correct": "It narrowed from 8.0% to 1.7%",
         "explanation": "The gap between leading open-weight and closed-weight models narrowed significantly from 8.0% to just 1.7% in one year[cite: 51, 126].",
        "topic": "Technical Performance"
    },
    {
        "question": "In 2024, how much private AI investment did the United States record compared to China?",
        "options": [
            "Nearly 2 times as much",
            "Nearly 5 times as much",
            "Nearly 12 times as much",
            "Nearly 24 times as much"
        ],
        "correct": "Nearly 12 times as much",
         "explanation": "U.S. private AI investment reached $109.1 billion, which is nearly 12 times China's $9.3 billion[cite: 35, 881].",
        "topic": "Economy and Investment"
    },
    {
        "question": "What percentage of global organizations reported using AI in their business operations in 2024?",
        "options": [
            "39%",
            "55%",
            "78%",
            "90%"
        ],
        "correct": "78%",
         "explanation": "Business adoption of AI accelerated from 55% in 2023 to 78% in 2024[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "How many AI-enabled medical devices were approved by the FDA in 2023?",
        "options": [
            "6",
            "59",
            "122",
            "223"
        ],
        "correct": "223",
         "explanation": "The FDA approved 223 AI-enabled medical devices in 2023, up from only six in 2015[cite: 33, 879].",
        "topic": "Science and Medicine"
    },
    {
        "question": "Which country reported the highest level of AI optimism in 2024, with 83% of the public seeing benefits over harms?",
        "options": [
            "United States",
            "Canada",
            "China",
            "Germany"
        ],
        "correct": "China",
         "explanation": "China leads global AI optimism at 83%, whereas the U.S. and Canada remain at or below 40%[cite: 47, 48, 896].",
        "topic": "Public Opinion"
    },
    {
        "question": "What was the recorded carbon emission for training the Llama 3.1 405B model in 2024?",
        "options": [
            "588 tons",
            "1,200 tons",
            "5,184 tons",
            "8,930 tons"
        ],
        "correct": "8,930 tons",
         "explanation": "Llama 3.1 405B training emitted 8,930 tons of carbon, compared to 5,184 tons for GPT-4[cite: 118].",
        "topic": "Environmental Impact"
    },
    {
        "question": "According to the report, how often does the training compute for notable AI models currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 5 months",
         "explanation": "Training compute for notable AI models is now doubling approximately every five months[cite: 63, 106].",
        "topic": "Hardware and Compute"
    },
    {
        "question": "How many AI-related regulations were introduced by U.S. federal agencies in 2024?",
        "options": [
            "15",
            "25",
            "59",
            "122"
        ],
        "correct": "59",
         "explanation": "U.S. federal agencies more than doubled their AI-related regulations to 59 in 2024[cite: 54, 903].",
        "topic": "Policy and Governance"
    },
    {
        "question": "What is the primary barrier to computer science education in many African countries as noted in the report?",
        "options": [
            "Lack of student interest",
            "High cost of AI software",
            "Basic infrastructure gaps like electricity",
            "Government bans on AI"
        ],
        "correct": "Basic infrastructure gaps like electricity",
         "explanation": "Infrastructure gaps, specifically electricity, remain a major barrier to CS education in many African nations[cite: 59, 908].",
        "topic": "Education"
    },
    {
        "question": "The inference cost for a system performing at the GPT-3.5 level dropped by how much between 2022 and 2024?",
        "options": [
            "10-fold",
            "50-fold",
            "100-fold",
            "Over 280-fold"
        ],
        "correct": "Over 280-fold",
         "explanation": "Inference costs dropped from $20.00 to $0.07 per million tokens, representing a more than 280-fold reduction[cite: 50, 108].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which country leads in total AI patents, accounting for nearly 70% of all grants globally as of 2023?",
        "options": [
            "United States",
            "Japan",
            "China",
            "South Korea"
        ],
        "correct": "China",
         "explanation": "China leads in total AI patents, accounting for 69.7% of all grants as of 2023[cite: 113].",
        "topic": "Research and Development"
    },
    {
        "question": "Which 2024 model from OpenAI utilizes 'test-time compute' to significantly improve mathematical reasoning?",
        "options": [
            "GPT-4o",
            "o1",
            "SORA",
            "Veo 2"
        ],
        "correct": "o1",
         "explanation": "OpenAI's o1 model uses test-time compute to reason through outputs, scoring 74.4% on a math qualifying exam[cite: 133, 134].",
        "topic": "Technical Performance"
    },
    {
        "question": "By what annual rate is the power required for training notable AI models increasing?",
        "options": [
            "It is doubling annually",
            "It is increasing by 10% annually",
            "It is decreasing by 40% annually",
            "It is staying flat"
        ],
        "correct": "It is doubling annually",
         "explanation": "The power required for training notable AI models is doubling on an annual basis[cite: 63, 106].",
        "topic": "Hardware and Compute"
    },
    {
        "question": "On the 'FrontierMath' benchmark, what percentage of complex mathematics problems can top AI systems solve?",
        "options": [
            "2%",
            "10%",
            "35%",
            "74%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely difficult benchmark where AI systems currently solve only 2% of problems[cite: 138].",
        "topic": "Technical Performance"
    },
    {
        "question": "What was the growth in global private investment for Generative AI specifically in 2024?",
        "options": [
            "5.4%",
            "11.9%",
            "18.7%",
            "29.6%"
        ],
        "correct": "18.7%",
         "explanation": "Generative AI private investment grew by 18.7% globally in 2024, reaching $33.9 billion[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which 2024 scientific milestone reflected the recognition of AI's role in chemistry?",
        "options": [
            "Turing Award for reinforcement learning",
            "Nobel Prize for protein folding applications",
            "Nobel Prize for semiconductor development",
            "Fields Medal for AI-driven math proofs"
        ],
        "correct": "Nobel Prize for protein folding applications",
         "explanation": "A 2024 Nobel Prize in Chemistry recognized AI's application to protein folding[cite: 66, 919].",
        "topic": "Science and Medicine"
    }
,
    {
        "question": "What percentage of 'notable' AI models were produced by the industry sector in 2024?",
        "options": [
            "30%",
            "60%",
            "75%",
            "90%"
        ],
        "correct": "90%",
         "explanation": "Industry's lead in notable model development grew significantly from 60% in 2023 to nearly 90% in 2024[cite: 95].",
        "topic": "Research and Development"
    },
    {
        "question": "Which institutional sector has remained the leading producer of highly cited (top 100) AI publications for the last three years?",
        "options": [
            "Industry",
            "Government",
            "Academia",
            "Non-profit Research"
        ],
        "correct": "Academia",
         "explanation": "Despite industry's lead in model production, academia remains the top source of highly cited research publications[cite: 96].",
        "topic": "Research and Development"
    },
    {
        "question": "By what percentage point margin did AI performance on the SWE-bench improve between 2023 and 2024?",
        "options": [
            "18.8 points",
            "48.9 points",
            "67.3 points",
            "22.3 points"
        ],
        "correct": "67.3 points",
         "explanation": "AI performance on the software engineering benchmark SWE-bench saw a massive leap of 67.3 percentage points in just one year[cite: 76, 123].",
        "topic": "Technical Performance"
    },
    {
        "question": "Which 2024 model demonstrated a 142-fold reduction in size compared to 2022 models while maintaining similar performance on the MMLU benchmark?",
        "options": [
            "Llama 3.1 8B",
            "GPT-4o mini",
            "Phi-3 Mini",
            "Gemini 1.5 Flash"
        ],
        "correct": "Phi-3 Mini",
         "explanation": "Microsoft's Phi-3 Mini (3.8B parameters) achieved thresholds previously reached by models 142 times larger, like PaLM[cite: 142].",
        "topic": "Model Efficiency"
    },
    {
        "question": "By February 2025, what was the performance gap between the leading closed-weight and open-weight models on the Chatbot Arena Leaderboard?",
        "options": [
            "8.0%",
            "5.4%",
            "1.7%",
            "0.7%"
        ],
        "correct": "1.7%",
         "explanation": "The performance gap between top open and closed models narrowed from 8.0% in early 2024 to just 1.7% by early 2025[cite: 125, 126].",
        "topic": "Technical Performance"
    },
    {
        "question": "What was the total private AI investment in the United States in 2024?",
        "options": [
            "$4.5 billion",
            "$9.3 billion",
            "$33.9 billion",
            "$109.1 billion"
        ],
        "correct": "$109.1 billion",
         "explanation": "U.S. private AI investment reached $109.1 billion in 2024, nearly 12 times more than China[cite: 35, 881].",
        "topic": "Economy and Investment"
    },
    {
        "question": "How many AI-enabled medical devices were approved by the FDA in 2023?",
        "options": [
            "6",
            "59",
            "122",
            "223"
        ],
        "correct": "223",
         "explanation": "FDA approvals for AI-enabled medical devices rose to 223 in 2023, up from just six in 2015[cite: 33, 879].",
        "topic": "Science and Medicine"
    },
    {
        "question": "Which country reported the highest level of public AI optimism in 2024?",
        "options": [
            "United States",
            "Indonesia",
            "China",
            "Thailand"
        ],
        "correct": "China",
         "explanation": "China leads global AI optimism at 83%, compared to countries like the U.S. at 39%[cite: 47, 896].",
        "topic": "Public Opinion"
    },
    {
        "question": "What is the primary reason for limited access to computer science education in many African countries?",
        "options": [
            "Lack of student interest",
            "Governmental bans on AI",
            "Basic infrastructure gaps like electricity",
            "High cost of software licenses"
        ],
        "correct": "Basic infrastructure gaps like electricity",
         "explanation": "Despite curriculum progress, basic infrastructure like electricity remains a major barrier to education in Africa[cite: 59, 908].",
        "topic": "Education"
    },
    {
        "question": "In 2024, which country launched 'Project Transcendence,' a $100 billion AI infrastructure initiative?",
        "options": [
            "China",
            "Canada",
            "France",
            "Saudi Arabia"
        ],
        "correct": "Saudi Arabia",
         "explanation": "Saudi Arabia's Project Transcendence represents a massive $100 billion investment in national AI infrastructure[cite: 55, 904].",
        "topic": "Policy and Governance"
    },
    {
        "question": "The inference cost for a system performing at the GPT-3.5 level dropped by how much between 2022 and 2024?",
        "options": [
            "10-fold",
            "100-fold",
            "More than 280-fold",
            "900-fold"
        ],
        "correct": "More than 280-fold",
         "explanation": "Inference costs fell from $20.00 to $0.07 per million tokens, a more than 280-fold reduction[cite: 50, 108].",
        "topic": "Economy and Investment"
    },
    {
        "question": "According to the report, how often does the training compute for notable AI models currently double?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 5 months",
         "explanation": "Training compute for notable AI models is now doubling approximately every five months[cite: 63, 106].",
        "topic": "Research and Development"
    },
    {
        "question": "What was the approximate carbon emission for training the Llama 3.1 405B model in 2024?",
        "options": [
            "588 tons",
            "5,184 tons",
            "8,930 tons",
            "12,000 tons"
        ],
        "correct": "8,930 tons",
         "explanation": "Training Llama 3.1 405B emitted 8,930 tons of carbon, significantly higher than previous models like GPT-4[cite: 118].",
        "topic": "Environmental Impact"
    },
    {
        "question": "Which new reasoning paradigm, involving models like OpenAI’s o1, allows AI to iteratively think through outputs?",
        "options": [
            "Zero-shot prompting",
            "Test-time compute",
            "Reinforcement learning from human feedback",
            "Few-shot learning"
        ],
        "correct": "Test-time compute",
         "explanation": "Models like o1 use test-time compute to iteratively reason, drastically improving math performance[cite: 132, 134].",
        "topic": "Technical Performance"
    },
    {
        "question": "How many AI-related regulations were introduced by U.S. federal agencies in 2024?",
        "options": [
            "25",
            "59",
            "109",
            "223"
        ],
        "correct": "59",
         "explanation": "U.S. federal agencies introduced 59 AI-related regulations in 2024, more than doubling the count from 2023[cite: 54, 903].",
        "topic": "Policy and Governance"
    },
    {
        "question": "What is the top AI system's performance on the rigorous 'Humanity's Last Exam' benchmark?",
        "options": [
            "2%",
            "8.80%",
            "35.50%",
            "71.70%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a difficult academic test where even the best system currently scores only 8.80%[cite: 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "As of 2024, what percentage of organizations reported using AI in their business?",
        "options": [
            "39%",
            "55%",
            "78%",
            "90%"
        ],
        "correct": "78%",
         "explanation": "Business adoption of AI increased from 55% in 2023 to 78% in 2024[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which country accounts for nearly 70% of all AI patent grants globally as of 2023?",
        "options": [
            "United States",
            "South Korea",
            "China",
            "Luxembourg"
        ],
        "correct": "China",
         "explanation": "China leads global AI patenting, accounting for 69.7% of all grants as of 2023[cite: 113].",
        "topic": "Research and Development"
    },
    {
        "question": "On the 'FrontierMath' benchmark, what percentage of complex problems can top AI systems solve?",
        "options": [
            "2%",
            "10%",
            "35%",
            "74%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely challenging benchmark where AI systems solve only 2% of problems[cite: 138].",
        "topic": "Technical Performance"
    },
    {
        "question": "Which 2024 scientific milestone recognized AI's contribution to protein folding?",
        "options": [
            "The Turing Award",
            "The Nobel Prize in Physics",
            "The Nobel Prize in Chemistry",
            "The Fields Medal"
        ],
        "correct": "The Nobel Prize in Chemistry",
         "explanation": "The Nobel Prize in Chemistry was awarded for work applying AI to protein folding[cite: 66, 919].",
        "topic": "Science and Medicine"
    }
,
    {
        "question": "Which specific AI-related concern saw the highest increase in public worry across G7 countries in 2024?",
        "options": [
            "Job loss to automation",
            "Lack of personal data privacy",
            "Deepfakes and misinformation",
            "Algorithmic bias in hiring"
        ],
        "correct": "Deepfakes and misinformation",
         "explanation": "The report highlights that misinformation and deepfakes are top concerns, particularly regarding their impact on global elections[cite: 23, 866].",
        "topic": "Responsible AI"
    },
    {
        "question": "In 2024, the United States federal government introduced how many AI-related regulations?",
        "options": [
            "25",
            "40",
            "59",
            "122"
        ],
        "correct": "59",
         "explanation": "U.S. federal agencies more than doubled their AI regulations to 59 in 2024, involving twice as many agencies as the previous year[cite: 54, 903].",
        "topic": "Policy and Governance"
    },
    {
        "question": "What was the percentage increase in AI legislative mentions across 75 countries between 2023 and 2024?",
        "options": [
            "5.4%",
            "11.9%",
            "21.3%",
            "41.8%"
        ],
        "correct": "21.3%",
         "explanation": "Legislative mentions of AI rose by 21.3% globally, marking a ninefold increase since 2016[cite: 55, 904].",
        "topic": "Policy and Governance"
    },
    {
        "question": "Which country launched a $100 billion national AI infrastructure initiative named 'Project Transcendence' in 2024?",
        "options": [
            "United States",
            "China",
            "Saudi Arabia",
            "France"
        ],
        "correct": "Saudi Arabia",
         "explanation": "Saudi Arabia's Project Transcendence is a massive $100 billion initiative aimed at expanding national AI infrastructure[cite: 55, 904].",
        "topic": "Policy and Governance"
    },
    {
        "question": "How many AI-enabled medical devices were approved by the FDA in 2023?",
        "options": [
            "6",
            "122",
            "223",
            "540"
        ],
        "correct": "223",
         "explanation": "The FDA approved 223 AI-enabled medical devices in 2023, showing a rapid increase from just six in 2015[cite: 33, 879].",
        "topic": "Science and Medicine"
    },
    {
        "question": "Which major scientific award in 2024 recognized the application of AI to protein folding?",
        "options": [
            "The Turing Award",
            "The Nobel Prize in Physics",
            "The Nobel Prize in Chemistry",
            "The Fields Medal"
        ],
        "correct": "The Nobel Prize in Chemistry",
         "explanation": "The 2024 Nobel Prize in Chemistry was awarded for work that applied deep learning to solve protein folding[cite: 66, 919].",
        "topic": "Science and Medicine"
    },
    {
        "question": "According to the report, what is the 'saturation' status of traditional AI benchmarks like MMLU and GSM8K?",
        "options": [
            "They are too difficult for current models",
            "They are becoming saturated as top models achieve near-perfect scores",
            "They are no longer used by industry",
            "They require too much compute to evaluate"
        ],
        "correct": "They are becoming saturated as top models achieve near-perfect scores",
         "explanation": "Traditional benchmarks are becoming saturated, leading to the creation of harder tests like 'Humanity's Last Exam'[cite: 136, 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "What is the recorded performance of AI systems on the 'FrontierMath' benchmark for complex mathematics?",
        "options": [
            "2%",
            "8.8%",
            "35.5%",
            "74.4%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is an extremely challenging benchmark where current AI systems solve only 2% of the problems[cite: 138].",
        "topic": "Technical Performance"
    },
    {
        "question": "By what factor did the inference cost for a GPT-3.5-level system drop between 2022 and 2024?",
        "options": [
            "10-fold",
            "50-fold",
            "100-fold",
            "Over 280-fold"
        ],
        "correct": "Over 280-fold",
         "explanation": "Costs fell from $20.00 to $0.07 per million tokens, representing a more than 280-fold reduction[cite: 108, 899].",
        "topic": "Economy and Investment"
    },
    {
        "question": "What percentage of global organizations reported adopting AI in their business operations in 2024?",
        "options": [
            "39%",
            "55%",
            "78%",
            "90%"
        ],
        "correct": "78%",
         "explanation": "Business adoption of AI accelerated significantly, rising from 55% in 2023 to 78% in 2024[cite: 36, 882].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which country reported the highest level of AI optimism, with 83% of the public seeing more benefits than harm?",
        "options": [
            "United States",
            "Canada",
            "China",
            "Netherlands"
        ],
        "correct": "China",
         "explanation": "China leads global AI optimism at 83%, whereas optimism in the U.S. and Canada is around 40%[cite: 47, 48, 896].",
        "topic": "Public Opinion"
    },
    {
        "question": "The power required for training notable AI models is doubling at what frequency?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 12 months",
         "explanation": "While training compute doubles every five months, the actual power required for training doubles annually[cite: 106, 912].",
        "topic": "Hardware and Efficiency"
    },
    {
        "question": "How did the performance gap between top open-weight and closed-weight models change in early 2025?",
        "options": [
            "It widened to 15%",
            "It remained at 8%",
            "It narrowed to 1.7%",
            "It was eliminated (0%)"
        ],
        "correct": "It narrowed to 1.7%",
         "explanation": "The gap on the Chatbot Arena Leaderboard narrowed from 8.0% in early 2024 to just 1.7% by February 2025[cite: 51, 126].",
        "topic": "Research and Development"
    },
    {
        "question": "Which institutional sector produced nearly 90% of notable AI models in 2024?",
        "options": [
            "Academia",
            "Government",
            "Industry",
            "Non-profit"
        ],
        "correct": "Industry",
         "explanation": "Industry's lead in notable model development grew to nearly 90% in 2024, up from 60% the previous year[cite: 62, 911].",
        "topic": "Research and Development"
    },
    {
        "question": "What is the primary barrier to computer science education in many African countries according to the report?",
        "options": [
            "Lack of teaching staff",
            "Infrastructure gaps like electricity",
            "Student disinterest",
            "High software license costs"
        ],
        "correct": "Infrastructure gaps like electricity",
         "explanation": "Basic infrastructure gaps, specifically electricity, remain a significant barrier to education in several African nations[cite: 59, 908].",
        "topic": "Education"
    },
    {
        "question": "What score did the top AI system achieve on the 'Humanity's Last Exam' benchmark?",
        "options": [
            "2.00%",
            "8.80%",
            "35.50%",
            "71.70%"
        ],
        "correct": "8.80%",
         "explanation": "Humanity's Last Exam is a rigorous test where the top system scores only 8.80%[cite: 137].",
        "topic": "Technical Performance"
    },
    {
        "question": "In 2024, how many notable AI models did U.S.-based institutions produce compared to China?",
        "options": [
            "40 (U.S.) vs 15 (China)",
            "15 (U.S.) vs 40 (China)",
            "25 (U.S.) vs 25 (China)",
            "40 (U.S.) vs 3 (China)"
        ],
        "correct": "40 (U.S.) vs 15 (China)",
         "explanation": "U.S. institutions produced 40 notable models, significantly outperforming China's 15[cite: 39, 885].",
        "topic": "Global Trends"
    },
    {
        "question": "By 2024, what was the success rate of AI systems on the SWE-bench coding benchmark?",
        "options": [
            "4.4%",
            "18.8%",
            "48.9%",
            "71.7%"
        ],
        "correct": "71.7%",
         "explanation": "AI performance on SWE-bench jumped from 4.4% in 2023 to 71.7% in 2024[cite: 123].",
        "topic": "Technical Performance"
    },
    {
        "question": "What was the private AI investment in the United Kingdom in 2024?",
        "options": [
            "$109.1 billion",
            "$33.9 billion",
            "$9.3 billion",
            "$4.5 billion"
        ],
        "correct": "$4.5 billion",
         "explanation": "The UK recorded $4.5 billion in private AI investment, compared to $109.1 billion in the US[cite: 35, 881].",
        "topic": "Economy and Investment"
    },
    {
        "question": "Which training-related metric for LLMs is currently doubling every eight months?",
        "options": [
            "Training compute",
            "Dataset size",
            "Power requirements",
            "Inference cost"
        ],
        "correct": "Dataset size",
         "explanation": "Research indicates that dataset sizes for training LLMs are doubling every eight months[cite: 106, 912].",
        "topic": "Hardware and Efficiency"
    }
,

    {
        "question": "According to the 2025 report, what is the 'saturation' issue currently affecting AI benchmarking?",
        "options": [
            "Models are becoming too large to be tested by standard hardware.",
            "Traditional benchmarks have become too easy for top-tier models to provide meaningful differentiation.",
            "There is a lack of diverse data to create new benchmarks.",
            "Public benchmarks are being hidden behind paywalls by private companies."
        ],
        "correct": "Traditional benchmarks have become too easy for top-tier models to provide meaningful differentiation.",
        "explanation": "The report notes that as models reach near-perfect scores on tests like MMLU, new and significantly harder benchmarks are required to measure progress.",
        "topic": "Strategic Trends in Technical Performance"
    },
    {
        "question": "What major shift in the 'open vs. closed' model debate was observed over the last year?",
        "options": [
            "Closed-source models have doubled the performance gap over open-source ones.",
            "Open-weight models are rapidly closing the performance gap with the best proprietary models.",
            "Open-source development has largely ceased due to high costs.",
            "Closed-source models have become entirely obsolete in industry settings."
        ],
        "correct": "Open-weight models are rapidly closing the performance gap with the best proprietary models.",
        "explanation": "The report highlights that the disparity between top open-weight and closed-source models is narrowing to a negligible margin.",
        "topic": "Strategic Trends in Research & Development"
    },
    {
        "question": "In the context of AI efficiency, what does the 'Phi-3 Mini' phenomenon illustrate regarding model development?",
        "options": [
            "Models must get larger to improve reasoning.",
            "Smaller, high-quality models can now achieve performance levels previously reserved for massive systems.",
            "Algorithm efficiency is declining as data sets grow.",
            "Small models are only useful for simple chatbots, not complex reasoning."
        ],
        "correct": "Smaller, high-quality models can now achieve performance levels previously reserved for massive systems.",
        "explanation": "The report shows that strategic algorithmic improvements allow much smaller models to match the benchmarks of older, larger predecessors.",
        "topic": "Model Efficiency & Architecture"
    },
    {
        "question": "What is the primary trend in the relationship between industry and academia in AI research?",
        "options": [
            "Academia has regained the lead in producing the most 'notable' large-scale models.",
            "Industry is increasingly dominating the production of frontier models due to compute requirements.",
            "Government labs have replaced industry as the primary source of innovation.",
            "Industry and academia have completely stopped collaborating on research."
        ],
        "correct": "Industry is increasingly dominating the production of frontier models due to compute requirements.",
        "explanation": "The report highlights that industry produced nearly 90% of notable models in 2024, driven by the massive resource requirements of frontier AI.",
        "topic": "Socioeconomic Landscape of Research"
    },
    {
        "question": "How has the nature of AI-related regulation changed globally in 2024?",
        "options": [
            "Regulation has slowed down as governments wait for the technology to mature.",
            "There is a sharp increase in the volume and diversity of AI-specific legal frameworks and agency rules.",
            "Countries are moving toward a single, unified global AI law.",
            "Regulations are now focusing exclusively on hardware rather than software applications."
        ],
        "correct": "There is a sharp increase in the volume and diversity of AI-specific legal frameworks and agency rules.",
        "explanation": "The report details a significant rise in AI-related legislative mentions and specific regulatory actions by federal agencies.",
        "topic": "Policy and Governance"
    },
    {
        "question": "What general trend does the report identify regarding AI's impact on the field of medicine?",
        "options": [
            "AI is primarily used for administrative tasks rather than clinical ones.",
            "The integration of AI into clinical practice is accelerating, particularly in diagnostic and medical device approvals.",
            "Medical AI has been restricted due to rising privacy concerns.",
            "AI has failed to improve the accuracy of medical imaging over traditional methods."
        ],
        "correct": "The integration of AI into clinical practice is accelerating, particularly in diagnostic and medical device approvals.",
        "explanation": "The massive increase in FDA-approved AI medical devices demonstrates AI's growing role in real-world healthcare.",
        "topic": "AI in Science and Medicine"
    },
    {
        "question": "Regarding AI hardware, what is a critical bottleneck identified in the 2025 report?",
        "options": [
            "A surplus of chips is leading to decreased investment.",
            "The rapidly increasing energy requirements for training and running large-scale models.",
            "A lack of software to utilize current hardware effectively.",
            "Physical space in data centers is no longer an issue."
        ],
        "correct": "The rapidly increasing energy requirements for training and running large-scale models.",
        "explanation": "The report emphasizes that training compute and the associated power requirements are doubling at an unsustainable annual rate.",
        "topic": "Hardware and Infrastructure"
    },
    {
        "question": "What is the 'Global South' perspective on AI infrastructure according to the report's summary?",
        "options": [
            "There is no interest in AI development in developing nations.",
            "Basic infrastructure gaps, such as electricity, remain the primary hurdle to AI adoption and education.",
            "Developing nations have already surpassed the West in AI infrastructure.",
            "Access to AI is universally distributed regardless of local infrastructure."
        ],
        "correct": "Basic infrastructure gaps, such as electricity, remain the primary hurdle to AI adoption and education.",
        "explanation": "The report notes that for many nations, foundational issues like power stability must be solved before AI can be effectively utilized.",
        "topic": "Global AI Disparities"
    },
    {
        "question": "What trend has been observed in the cost of AI development and deployment?",
        "options": [
            "Inference costs are rising as models become more complex.",
            "Training costs for frontier models are decreasing significantly.",
            "While training costs for top models are soaring, the cost of using existing models (inference) is plummeting.",
            "Hardware costs are the only factor that has remained stable."
        ],
        "correct": "While training costs for top models are soaring, the cost of using existing models (inference) is plummeting.",
        "explanation": "The report shows that while leading models cost hundreds of millions to train, the efficiency of running them has improved by several orders of magnitude.",
        "topic": "Economy and Investment"
    },
    {
        "question": "How is the public's perception of AI evolving globally?",
        "options": [
            "The public is becoming universally more optimistic about AI.",
            "There is a growing divide in sentiment, with high optimism in emerging economies and more caution in Western nations.",
            "Public interest in AI has peaked and is now declining.",
            "Fear of AI has been completely replaced by excitement regarding job creation."
        ],
        "correct": "There is a growing divide in sentiment, with high optimism in emerging economies and more caution in Western nations.",
        "explanation": "The report documents high optimism in countries like China and Indonesia, contrasted with significant concern in the U.S. and Europe.",
        "topic": "Public Opinion and Society"
    },
    {
        "question": "What does the report suggest about the 'reasoning' capabilities of current AI models?",
        "options": [
            "AI has fully solved the problem of logical reasoning.",
            "Models are shifting toward 'test-time compute' to simulate more complex reasoning processes.",
            "Current models have reached a plateau where reasoning cannot be improved.",
            "Reasoning is becoming less important than simple pattern recognition."
        ],
        "correct": "Models are shifting toward 'test-time compute' to simulate more complex reasoning processes.",
        "explanation": "New paradigms like those used in the 'o1' model series show that 'thinking' longer during inference can yield better logical results.",
        "topic": "Strategic Trends in Technical Performance"
    },
    {
        "question": "In the workforce, what is the reported trend regarding AI and productivity?",
        "options": [
            "AI has led to a decrease in overall worker efficiency.",
            "Early studies suggest AI can significantly boost productivity, especially for lower-skilled workers.",
            "AI only benefits highly specialized software engineers.",
            "No measurable productivity gains have been found in the 2024 data."
        ],
        "correct": "Early studies suggest AI can significantly boost productivity, especially for lower-skilled workers.",
        "explanation": "The report cites multiple studies showing that AI tools help bridge the skill gap and increase the speed of routine professional tasks.",
        "topic": "Economy and Investment"
    },
    {
        "question": "What is the primary concern regarding 'Deepfakes' highlighted in the 2025 summary?",
        "options": [
            "They are too expensive to produce.",
            "They are easily detectable by current consumer software.",
            "Their potential to undermine trust in information and disrupt political processes.",
            "They are used primarily for harmless entertainment purposes."
        ],
        "correct": "Their potential to undermine trust in information and disrupt political processes.",
        "explanation": "The report notes that the ease of creating high-quality synthetic media is a top concern for global governance and social stability.",
        "topic": "Responsible AI"
    },
    {
        "question": "What does the report conclude about the use of AI in scientific discovery?",
        "options": [
            "AI is slowing down the scientific process due to errors.",
            "AI is becoming a core tool in 'hard' sciences like physics and chemistry, leading to Nobel-caliber breakthroughs.",
            "Scientific AI is limited strictly to data entry.",
            "AI has been banned from most academic research journals."
        ],
        "correct": "AI is becoming a core tool in 'hard' sciences like physics and chemistry, leading to Nobel-caliber breakthroughs.",
        "explanation": "The report highlights major wins in protein folding and materials science as evidence of AI's transformative role in research.",
        "topic": "AI in Science and Medicine"
    },
    {
        "question": "What trend is emerging in 'National AI Strategies' globally?",
        "options": [
            "Countries are focusing less on AI and more on traditional manufacturing.",
            "There is a race to build 'sovereign AI' through massive government-led infrastructure investments.",
            "Nations are agreeing to stop investing in AI hardware to save energy.",
            "National strategies are focusing only on banning AI in schools."
        ],
        "correct": "There is a race to build 'sovereign AI' through massive government-led infrastructure investments.",
        "explanation": "As seen with projects in Saudi Arabia and various European initiatives, nations are treating AI compute as a critical national resource.",
        "topic": "Policy and Governance"
    },
    {
        "question": "Regarding AI education, what shift is occurring in the academic world?",
        "options": [
            "Interest in AI-related degrees is declining.",
            "AI is being integrated across diverse disciplines, not just in computer science departments.",
            "Universities are removing AI from the curriculum due to cheating concerns.",
            "Most AI education is now happening outside of traditional universities."
        ],
        "correct": "AI is being integrated across diverse disciplines, not just in computer science departments.",
        "explanation": "The report notes that AI literacy is becoming a requirement across many fields of study beyond engineering.",
        "topic": "Education"
    },
    {
        "question": "What is the main takeaway regarding the 'Environmental Impact' of AI?",
        "options": [
            "AI development has no measurable impact on the environment.",
            "The carbon footprint of training the largest models is growing, but hardware efficiency is also improving.",
            "AI is the primary cause of global water shortages.",
            "Models are now exclusively trained using carbon-neutral energy."
        ],
        "correct": "The carbon footprint of training the largest models is growing, but hardware efficiency is also improving.",
        "explanation": "While emissions for top-tier models are high, the report notes that efficiency gains are partially offsetting the total environmental cost.",
        "topic": "Hardware and Infrastructure"
    },
    {
        "question": "In the corporate world, what is the primary shift in AI adoption?",
        "options": [
            "Most companies have stopped using AI after initial pilot failures.",
            "AI has moved from an experimental 'hype' phase to a widespread operational tool integrated into business processes.",
            "Only tech giants are using AI, while small businesses remain unaffected.",
            "Companies are using AI solely for customer service bots."
        ],
        "correct": "AI has moved from an experimental 'hype' phase to a widespread operational tool integrated into business processes.",
        "explanation": "The jump in organizations reporting AI use indicates that the technology is now a standard part of corporate strategy.",
        "topic": "Economy and Investment"
    },
    {
        "question": "What does the report suggest about the future of AI 'Self-Correction' and safety?",
        "options": [
            "Models have become perfectly safe and no longer require human oversight.",
            "Developing reliable methods for AI to detect and fix its own errors remains a major research challenge.",
            "Safety research has been largely abandoned in favor of speed.",
            "AI is now legally required to be 100% accurate in all jurisdictions."
        ],
        "correct": "Developing reliable methods for AI to detect and fix its own errors remains a major research challenge.",
        "explanation": "The report emphasizes that 'high-stakes' reliability is still an unsolved problem in AI safety research.",
        "topic": "Responsible AI"
    },
    {
        "question": "What major trend is observed in 'Multi-modal' AI development?",
        "options": [
            "Models are becoming more specialized, focusing only on text or only on images.",
            "Frontier models are increasingly 'native' multi-modal, processing text, audio, and video simultaneously.",
            "Multi-modal AI has proven to be less effective than text-only models.",
            "Video generation has been removed from most major AI platforms."
        ],
        "correct": "Frontier models are increasingly 'native' multi-modal, processing text, audio, and video simultaneously.",
        "explanation": "The latest models are designed to understand and generate across all media types in a single architecture.",
        "topic": "Strategic Trends in Technical Performance"
    }
,
    {
        "question": "What is the primary trend regarding the 'frontier' of AI model performance according to the 2025 report?",
        "options": [
            "A single developer has established an insurmountable lead.",
            "The performance gap between the top-ranked models is rapidly shrinking.",
            "Model performance has reached a permanent plateau.",
            "Open-source models have completely surpassed closed-source models."
        ],
        "correct": "The performance gap between the top-ranked models is rapidly shrinking.",
         "explanation": "The report highlights that the frontier is becoming increasingly crowded and competitive, with narrowing Elo score differences between top models[cite: 64, 913, 914].",
        "topic": "Strategic Trends in AI Performance"
    },
    {
        "question": "How has the institutional landscape of 'notable' AI model development changed between 2023 and 2024?",
        "options": [
            "Academia has regained the lead from industry.",
            "Government agencies now produce the majority of frontier models.",
            "Industry's dominance in producing notable models has significantly increased.",
            "Non-profit organizations have become the primary developers."
        ],
        "correct": "Industry's dominance in producing notable models has significantly increased.",
         "explanation": "Industry's share of notable model development grew from 60% in 2023 to nearly 90% in 2024[cite: 62, 95, 911].",
        "topic": "Socioeconomic Trends in Research"
    },
    {
        "question": "What does the 2025 report identify as a major shift in the 'open vs. closed' model debate?",
        "options": [
            "Closed-weight models are widening their performance lead.",
            "Open-weight models are now significantly more expensive to run.",
            "The performance gap between top open-weight and closed-weight models has nearly disappeared.",
            "Open-weight models are no longer being released by major developers."
        ],
        "correct": "The performance gap between top open-weight and closed-weight models has nearly disappeared.",
         "explanation": "The gap narrowed from 8.0% in early 2024 to just 1.7% by early 2025, lowering barriers to advanced AI[cite: 51, 125, 126, 900].",
        "topic": "Strategic Trends in Technical Performance"
    },
    {
        "question": "Which trend best describes the current state of AI benchmarking as noted in the summary?",
        "options": [
            "Benchmarks are becoming easier to create due to AI automation.",
            "Traditional benchmarks are becoming 'saturated' as models achieve near-perfect scores.",
            "Benchmarks are no longer considered a reliable way to measure progress.",
            "The industry has agreed on a single, permanent benchmark for all models."
        ],
        "correct": "Traditional benchmarks are becoming 'saturated' as models achieve near-perfect scores.",
         "explanation": "The saturation of older tests has pushed researchers to develop more rigorous academic and math-focused benchmarks[cite: 136, 137, 138].",
        "topic": "Strategic Trends in Technical Performance"
    },
    {
        "question": "In terms of global R&D, what role does academia continue to play despite industry's lead in model production?",
        "options": [
            "Academia leads in funding large-scale compute clusters.",
            "Academia remains the primary source of highly cited research publications.",
            "Academia has shifted entirely to AI ethics and policy.",
            "Academia no longer contributes significantly to AI research."
        ],
        "correct": "Academia remains the primary source of highly cited research publications.",
         "explanation": "While industry leads in model building, academia has remained the top producer of highly influential (top 100) research[cite: 62, 96, 911].",
        "topic": "Socioeconomic Trends in Research"
    },
    {
        "question": "What major trend is observed in the geographical landscape of AI model quality between the U.S. and China?",
        "options": [
            "The U.S. has significantly widened its quality lead.",
            "China has surpassed the U.S. in both quantity and quality.",
            "Chinese models have rapidly closed the performance gap on major benchmarks.",
            "European models have overtaken both U.S. and Chinese models."
        ],
        "correct": "Chinese models have rapidly closed the performance gap on major benchmarks.",
         "explanation": "Performance differences on benchmarks like MMLU and HumanEval shrank from double digits to near parity in 2024[cite: 40, 128, 129, 886].",
        "topic": "Geopolitical Trends in AI"
    },
    {
        "question": "How has the 'Turing Test' been characterized by the AI Index co-directors in 2025?",
        "options": [
            "It remains the 'gold standard' for AI intelligence.",
            "It has been surpassed by today's systems and is no longer an ambitious goal.",
            "It has been proven mathematically impossible to pass.",
            "It is the primary benchmark used for government regulation."
        ],
        "correct": "It has been surpassed by today's systems and is no longer an ambitious goal.",
         "explanation": "Sophisticated modern systems have exceeded the test, making it a less useful metric for frontier AI[cite: 15, 858].",
        "topic": "Strategic Trends in AI Development"
    },
    {
        "question": "What shift has occurred in the business world regarding AI adoption as of 2024?",
        "options": [
            "Businesses are becoming more skeptical due to high costs.",
            "Adoption has slowed down as companies wait for regulation.",
            "AI has moved from the margins to become a central driver of business value and usage.",
            "Most companies have replaced their entire workforce with AI."
        ],
        "correct": "AI has moved from the margins to become a central driver of business value and usage.",
         "explanation": "Business adoption accelerated significantly in 2024, rising from 55% to 78% of organizations[cite: 18, 36, 861, 882].",
        "topic": "Economic Trends"
    },
    {
        "question": "According to the report, what is the 'scaling' trend for training compute and data?",
        "options": [
            "Compute and data needs have stabilized and are now decreasing.",
            "Training compute, dataset sizes, and power use are all doubling at rapid, short-term intervals.",
            "Data is doubling, but compute needs are staying flat due to efficiency.",
            "Scaling has stopped due to environmental regulations."
        ],
        "correct": "Training compute, dataset sizes, and power use are all doubling at rapid, short-term intervals.",
         "explanation": "Compute doubles every 5 months, datasets every 8 months, and power use annually[cite: 63, 106, 912].",
        "topic": "Infrastructure and Scaling"
    },
    {
        "question": "What is the primary barrier to AI education in developing regions like Africa, despite curriculum progress?",
        "options": [
            "Lack of interest from students.",
            "Governmental bans on AI technology.",
            "Basic infrastructure gaps such as unreliable electricity.",
            "The high cost of AI textbooks."
        ],
        "correct": "Basic infrastructure gaps such as unreliable electricity.",
         "explanation": "Infrastructure remains the primary hurdle for expanding computer science education in many African nations[cite: 59, 908].",
        "topic": "AI Education and Access"
    },
    {
        "question": "What does the 2025 report conclude about AI's impact on worker productivity?",
        "options": [
            "AI has no measurable impact on productivity yet.",
            "AI boosts productivity and generally helps narrow skill gaps in the workforce.",
            "AI primarily benefits only the most highly skilled workers.",
            "AI has led to a global decrease in professional work quality."
        ],
        "correct": "AI boosts productivity and generally helps narrow skill gaps in the workforce.",
         "explanation": "Research confirms productivity gains and indicates that AI often assists lower-skilled workers in catching up[cite: 37, 883].",
        "topic": "Economic Trends"
    },
    {
        "question": "How has global public optimism regarding AI shifted according to 2024 surveys?",
        "options": [
            "Optimism is declining universally due to job fears.",
            "There is a sharp divide between high optimism in emerging economies and lower optimism in the West.",
            "The U.S. and Canada are now the most optimistic nations regarding AI.",
            "Sentiment has become entirely uniform across all regions."
        ],
        "correct": "There is a sharp divide between high optimism in emerging economies and lower optimism in the West.",
         "explanation": "Countries like China and Thailand show high optimism (above 75%), while Western nations remain much more skeptical[cite: 46, 47, 48, 895, 896, 897].",
        "topic": "Public Opinion"
    },
    {
        "question": "What major trend is occurring in AI-related government policy globally?",
        "options": [
            "Governments are deregulating to encourage faster growth.",
            "Policy is shifting from mere debate to large-scale infrastructure investment and regulation.",
            "Most countries have decided to ban AI in public sectors.",
            "Policy has become less important as private companies take over governance."
        ],
        "correct": "Policy is shifting from mere debate to large-scale infrastructure investment and regulation.",
         "explanation": "Several countries have launched billion-dollar initiatives and significantly increased regulatory actions[cite: 19, 20, 53, 54, 862, 863].",
        "topic": "Policy and Governance"
    },
    {
        "question": "Which area of AI performance remains a significant challenge for modern systems in high-stakes settings?",
        "options": [
            "Basic text generation and summarization.",
            "Generating high-quality video from text.",
            "Reliably solving complex logic and reasoning tasks.",
            "Outperforming humans in simple programming tasks."
        ],
        "correct": "Reliably solving complex logic and reasoning tasks.",
         "explanation": "Models still struggle with precision in reasoning benchmarks like PlanBench, which limits their use where precision is critical[cite: 67, 68, 920, 921].",
        "topic": "Technical Challenges"
    },
    {
        "question": "How has the 'accessibility' of advanced AI changed over the last two years?",
        "options": [
            "It has decreased as costs have skyrocketed.",
            "It has increased due to massive reductions in inference costs and the rise of capable small models.",
            "It is now restricted only to government researchers.",
            "It has remained stagnant since 2022."
        ],
        "correct": "It has increased due to massive reductions in inference costs and the rise of capable small models.",
         "explanation": "Inference costs for GPT-3.5 level systems dropped over 280-fold, significantly lowering entry barriers[cite: 50, 52, 108, 899, 901].",
        "topic": "Economic Trends"
    },
    {
        "question": "What does the 2025 report identify as a key trend in 'Responsible AI' (RAI) among corporations?",
        "options": [
            "Most companies have fully implemented standardized RAI evaluations.",
            "A gap persists between companies recognizing RAI risks and taking meaningful action.",
            "Corporations have abandoned RAI in favor of faster model deployment.",
            "RAI is now entirely managed by government-mandated AI agents."
        ],
        "correct": "A gap persists between companies recognizing RAI risks and taking meaningful action.",
         "explanation": "While risk recognition is growing, the implementation of standardized evaluations and concrete actions remains uneven[cite: 44, 45, 890, 891].",
        "topic": "Responsible AI"
    },
    {
        "question": "What is the trend for AI hardware according to the research cited in the report?",
        "options": [
            "Hardware is getting more expensive and less efficient over time.",
            "Hardware performance is growing annually while costs are dropping and energy efficiency is improving.",
            "Hardware development has reached a physical limit and stopped.",
            "Energy efficiency is the only metric that is not improving."
        ],
        "correct": "Hardware performance is growing annually while costs are dropping and energy efficiency is improving.",
         "explanation": "Performance grows 43% annually, costs drop 30%, and efficiency increases by 40%[cite: 115, 116, 899].",
        "topic": "Infrastructure and Scaling"
    },
    {
        "question": "Which development best illustrates AI's growing role in 'everyday life' in 2024?",
        "options": [
            "The move of technologies like robotaxis and AI medical devices from experimental labs to daily public use.",
            "The use of AI exclusively for military simulations.",
            "The complete replacement of the internet with AI-generated content.",
            "A decrease in the number of people using AI tools for professional work."
        ],
        "correct": "The move of technologies like robotaxis and AI medical devices from experimental labs to daily public use.",
         "explanation": "The report cites 223 FDA-approved devices and 150,000+ weekly robotaxi rides as evidence[cite: 33, 878, 879].",
        "topic": "AI Integration and Society"
    },
    {
        "question": "What is the 'test-time compute' approach and why is it significant in 2024?",
        "options": [
            "It is a way to make models smaller for mobile devices.",
            "It allows models to 'think' longer and reason through outputs, dramatically boosting performance on complex tasks.",
            "It is a method for reducing the carbon footprint of AI training.",
            "It is a new law that restricts how much compute a company can use for testing."
        ],
        "correct": "It allows models to 'think' longer and reason through outputs, dramatically boosting performance on complex tasks.",
         "explanation": "Models like OpenAI's o1 use this approach to significantly improve results in areas like mathematics[cite: 132, 133, 134].",
        "topic": "Technical Innovations"
    },
    {
        "question": "What has been the impact of AI on the global scientific community in 2024?",
        "options": [
            "AI has been largely ignored by major scientific bodies.",
            "AI's importance was underscored by multiple Nobel Prizes for physics and chemistry and the Turing Award.",
            "AI has replaced all human scientists in the field of protein folding.",
            "The scientific community has called for a permanent halt to AI research."
        ],
        "correct": "AI's importance was underscored by multiple Nobel Prizes for physics and chemistry and the Turing Award.",
         "explanation": "The recognition of AI's role in deep learning and protein folding shows its foundational impact on science[cite: 14, 66, 857, 919].",
        "topic": "AI in Science and Medicine"
    }
,
    {
        "question": "What is the primary trend regarding the performance gap between top open-weight and closed-weight models in 2024?",
        "options": [
            "Closed-weight models have doubled their performance lead.",
            "Open-weight models are rapidly catching up to proprietary leaders.",
            "Open-weight development has ceased due to high costs.",
            "There is no longer any difference in how models are trained."
        ],
        "correct": "Open-weight models are rapidly catching up to proprietary leaders.",
        "explanation": "The report highlights that the disparity between open and closed models narrowed to a negligible margin in 2024, democratizing access to frontier-level AI.",
        "topic": "Strategic Trends in Research"
    },
    {
        "question": "How has the 'notable' AI model development landscape shifted between industry and academia?",
        "options": [
            "Academia has regained the lead in producing frontier models.",
            "Industry dominance has intensified, producing the vast majority of notable models.",
            "Government labs now lead in AI model production.",
            "Non-profits have become the primary source of AI innovation."
        ],
        "correct": "Industry dominance has intensified, producing the vast majority of notable models.",
        "explanation": "Industry's share of notable model development reached nearly 90% in 2024, driven by the massive compute resources required.",
        "topic": "Industry vs. Academia"
    },
    {
        "question": "What does the 2025 report identify as a key trend in 'Model Efficiency'?",
        "options": [
            "Models must always get larger to improve.",
            "Smaller models are achieving performance levels that previously required massive systems.",
            "Algorithmic efficiency is declining as datasets grow.",
            "Inference costs are rising despite smaller model sizes."
        ],
        "correct": "Smaller models are achieving performance levels that previously required massive systems.",
        "explanation": "The report highlights a significant 'reduction' trend where compact models now match the benchmarks of much larger predecessors from just two years ago.",
        "topic": "Model Efficiency"
    },
    {
        "question": "In the context of AI benchmarks, what is meant by the term 'saturation'?",
        "options": [
            "Models are processing too much data for the tests to handle.",
            "Standard tests have become too easy for frontier models, losing their ability to differentiate performance.",
            "There are too many benchmarks for researchers to track.",
            "Public benchmarks have been completely replaced by private corporate testing."
        ],
        "correct": "Standard tests have become too easy for frontier models, losing their ability to differentiate performance.",
        "explanation": "The saturation of traditional benchmarks like MMLU has forced the creation of much harder tests to measure true progress.",
        "topic": "Technical Performance Metrics"
    },
    {
        "question": "What trend is emerging in the way AI models 'reason' through complex problems?",
        "options": [
            "Models are relying more on simple pattern matching.",
            "A shift toward 'test-time compute' allows models to spend more time thinking before answering.",
            "Reasoning has been de-prioritized in favor of creative writing.",
            "Models are now hard-coded with logical rules to prevent errors."
        ],
        "correct": "A shift toward 'test-time compute' allows models to spend more time thinking before answering.",
        "explanation": "Newer models use additional compute during the inference phase to iteratively reason, which significantly boosts math and logic performance.",
        "topic": "Technical Innovation"
    },
    {
        "question": "What is the general trend for global AI private investment outside of the United States?",
        "options": [
            "Investment is increasing everywhere at the same rate.",
            "Most regions are seeing a decline or stagnation compared to the massive growth in the U.S.",
            "China has surpassed the U.S. in total private investment.",
            "Private investment has been replaced by government funding globally."
        ],
        "correct": "Most regions are seeing a decline or stagnation compared to the massive growth in the U.S.",
        "explanation": "While the U.S. saw a massive investment surge, other major regions like China and the UK experienced significant declines or much slower growth.",
        "topic": "Economic Trends"
    },
    {
        "question": "How is the public's perception of AI evolving globally as of 2024?",
        "options": [
            "Public sentiment is becoming universally negative.",
            "A sharp divide exists between high optimism in emerging economies and caution in Western nations.",
            "Optimism is highest in the U.S. and Europe.",
            "Sentiment is uniform across all countries due to social media."
        ],
        "correct": "A sharp divide exists between high optimism in emerging economies and caution in Western nations.",
        "explanation": "The report shows that countries like China and Indonesia remain highly optimistic, while Western nations express more concern over risks.",
        "topic": "Public Opinion"
    },
    {
        "question": "What is a major bottleneck identified for AI expansion in developing nations?",
        "options": [
            "A lack of interest from the general public.",
            "Fundamental infrastructure gaps, such as reliable access to electricity.",
            "High costs of open-source software licenses.",
            "Governmental bans on all automated systems."
        ],
        "correct": "Fundamental infrastructure gaps, such as reliable access to electricity.",
        "explanation": "The report notes that basic infrastructure remains the primary hurdle for AI adoption in regions like Africa.",
        "topic": "Global Infrastructure"
    },
    {
        "question": "Regarding AI hardware, what trend is described in the 2025 report summary?",
        "options": [
            "Hardware is becoming more specialized and less efficient.",
            "The performance of AI chips is growing annually while costs per unit of performance are dropping.",
            "The industry has switched back to general-purpose CPUs for training.",
            "Energy efficiency for AI chips has reached a physical limit and stopped improving."
        ],
        "correct": "The performance of AI chips is growing annually while costs per unit of performance are dropping.",
        "explanation": "Hardware continues to follow a trend of increasing performance and declining costs, though total energy use remains high.",
        "topic": "Hardware Trends"
    },
    {
        "question": "What does the 2025 report conclude about the use of AI in scientific research?",
        "options": [
            "AI is primarily used for administrative tasks in science.",
            "AI is becoming a transformative tool for core discoveries in fields like chemistry and physics.",
            "Most scientists are moving away from AI due to reliability concerns.",
            "AI has not yet contributed to any major scientific awards."
        ],
        "correct": "AI is becoming a transformative tool for core discoveries in fields like chemistry and physics.",
        "explanation": "The recognition of AI-driven breakthroughs with Nobel Prizes in 2024 signals its fundamental role in modern science.",
        "topic": "AI in Science"
    },
    {
        "question": "What is the trend for 'Inference Costs' (running AI models) as of late 2024?",
        "options": [
            "Costs are rising due to model complexity.",
            "Costs have plummeted, making advanced AI significantly more accessible to small businesses.",
            "Inference is now free for all users globally.",
            "Costs have stayed the same since the release of GPT-3."
        ],
        "correct": "Costs have plummeted, making advanced AI significantly more accessible to small businesses.",
        "explanation": "Massive reductions in inference costs (over 200-fold in some cases) have lowered the barriers to entry for AI integration.",
        "topic": "Economic Trends"
    },
    {
        "question": "How has AI regulation changed at the governmental level in 2024?",
        "options": [
            "Regulation has decreased to encourage faster innovation.",
            "There has been a surge in AI-related legislative activity and executive rulemaking globally.",
            "Governments have decided to let AI companies self-regulate entirely.",
            "Most countries have banned AI in the public sector."
        ],
        "correct": "There has been a surge in AI-related legislative activity and executive rulemaking globally.",
        "explanation": "The report documents a significant rise in AI-specific laws and regulatory actions by federal agencies.",
        "topic": "Policy and Governance"
    },
    {
        "question": "What is the primary concern regarding 'Responsible AI' within corporations as of 2024?",
        "options": [
            "Companies are over-investing in safety at the expense of performance.",
            "There is a gap between acknowledging AI risks and implementing concrete safety protocols.",
            "Corporations have largely solved the problem of algorithmic bias.",
            "Responsible AI is no longer a priority for major tech firms."
        ],
        "correct": "There is a gap between acknowledging AI risks and implementing concrete safety protocols.",
        "explanation": "While risk awareness is up, the standardized implementation of responsible AI practices remains inconsistent across industries.",
        "topic": "Responsible AI"
    },
    {
        "question": "What major trend is observed in 'Multi-modal' AI systems?",
        "options": [
            "Models are becoming more specialized, only handling text.",
            "Native multi-modality—processing text, audio, and video together—is becoming the new standard.",
            "Video generation has been separated from language models for safety.",
            "Multi-modal models have proven to be less efficient than single-mode ones."
        ],
        "correct": "Native multi-modality—processing text, audio, and video together—is becoming the new standard.",
        "explanation": "Frontier models are increasingly designed to understand and generate across all media types within a single architecture.",
        "topic": "Technical Trends"
    },
    {
        "question": "How is AI impacting the software engineering field according to the 2025 report?",
        "options": [
            "AI has led to a decrease in coding productivity.",
            "AI agents are showing massive leaps in solving real-world software engineering tasks.",
            "The use of AI in coding has been banned by most major tech companies.",
            "AI is only useful for writing documentation, not actual code."
        ],
        "correct": "AI agents are showing massive leaps in solving real-world software engineering tasks.",
        "explanation": "Performance on coding benchmarks like SWE-bench saw unprecedented growth, indicating a shift toward more autonomous coding assistants.",
        "topic": "AI in Software Engineering"
    },
    {
        "question": "What trend is emerging in 'National AI Strategies' globally?",
        "options": [
            "Countries are focusing less on AI and more on manual labor.",
            "A shift toward building 'Sovereign AI' through massive national infrastructure investments.",
            "Nations are agreeing to stop all AI development to protect jobs.",
            "AI strategies are focusing only on banning the technology in schools."
        ],
        "correct": "A shift toward building 'Sovereign AI' through massive national infrastructure investments.",
        "explanation": "Countries are increasingly treating AI compute and data as critical national resources, leading to multi-billion dollar domestic projects.",
        "topic": "Policy and Governance"
    },
    {
        "question": "What is the trend regarding the energy consumption of AI training?",
        "options": [
            "Energy use is decreasing significantly due to better chips.",
            "The power required for training frontier models is doubling annually.",
            "AI training has become carbon-neutral across the entire industry.",
            "Governments have successfully capped AI energy use."
        ],
        "correct": "The power required for training frontier models is doubling annually.",
        "explanation": "Despite efficiency gains, the massive scale of training compute means the total power requirement continues to climb rapidly.",
        "topic": "Environmental Impact"
    },
    {
        "question": "In terms of worker productivity, what does the report highlight?",
        "options": [
            "AI only benefits top-tier management.",
            "AI has the potential to bridge skill gaps by helping lower-skilled workers more significantly.",
            "Productivity has dropped as workers spend too much time 'fixing' AI errors.",
            "There is no evidence that AI helps with professional tasks."
        ],
        "correct": "AI has the potential to bridge skill gaps by helping lower-skilled workers more significantly.",
        "explanation": "Studies cited in the report suggest that AI tools often provide a greater relative boost to less-experienced employees.",
        "topic": "Economy and Workforce"
    },
    {
        "question": "What shift has occurred in the accessibility of advanced medical AI tools?",
        "options": [
            "They are being restricted to research labs only.",
            "There is a rapid increase in the number of AI-enabled medical devices approved for clinical use.",
            "Medical AI has been proven to be less accurate than human-only diagnosis.",
            "The cost of medical AI has made it inaccessible to most hospitals."
        ],
        "correct": "There is a rapid increase in the number of AI-enabled medical devices approved for clinical use.",
        "explanation": "The steady rise in FDA approvals marks the transition of AI from a theoretical tool to a standard clinical resource.",
        "topic": "AI in Medicine"
    },
    {
        "question": "What is the primary conclusion regarding AI 'Safety' research in the 2025 summary?",
        "options": [
            "AI models are now 100% safe for all high-stakes tasks.",
            "Reliable safety evaluations and the prevention of hallucinations remain unsolved frontier challenges.",
            "Safety research has been largely completed.",
            "Companies have stopped doing safety research to save money."
        ],
        "correct": "Reliable safety evaluations and the prevention of hallucinations remain unsolved frontier challenges.",
        "explanation": "The report emphasizes that while models are more capable, making them consistently safe and truthful remains a major focus of ongoing research.",
        "topic": "Responsible AI"
    }
,
    {
        "question": "What does the term 'test-time compute' refer to in the context of recent AI models like OpenAI's o1?",
        "options": [
            "The amount of energy used to train the model.",
            "A paradigm where models spend more time iteratively reasoning through an output at inference time.",
            "The speed at which a model generates its first token.",
            "A method for compressing a large model into a mobile-friendly version."
        ],
        "correct": "A paradigm where models spend more time iteratively reasoning through an output at inference time.",
         "explanation": "Test-time compute allows models to 'think' longer before responding, significantly boosting scores on complex reasoning tasks[cite: 132, 133].",
        "topic": "Advanced Model Paradigms"
    },
    {
        "question": "By what factor did inference costs for a GPT-3.5-level system drop between late 2022 and late 2024?",
        "options": [
            "10-fold",
            "50-fold",
            "100-fold",
            "Over 280-fold"
        ],
        "correct": "Over 280-fold",
          "explanation": "Inference costs fell from $20.00 to just $0.07 per million tokens, a more than 280-fold reduction in 18 months[cite: 108].",
        "topic": "The Inference Economy"
    },
    {
        "question": "According to the report, how has the performance of AI 'agents' changed on the SWE-bench coding benchmark between 2023 and 2024?",
        "options": [
            "It decreased due to model hallucinations.",
            "It increased by a staggering 67.3 percentage points.",
            "It remained stagnant at roughly 4.4%.",
            "It reached human parity at 97%."
        ],
        "correct": "It increased by a staggering 67.3 percentage points.",
           "explanation": "AI performance on the software engineering benchmark SWE-bench jumped from 4.4% in 2023 to 71.7% in 2024[cite: 30, 123].",
        "topic": "AI Agents and Software Engineering"
    },
    {
        "question": "What is a primary characteristic of the 'frontier' of AI model performance in early 2025?",
        "options": [
            "A widening gap between the #1 and #10 ranked models.",
            "Extreme performance convergence, with top models separated by as little as 0.7%.",
            "A complete halt in performance gains on math benchmarks.",
            "The total disappearance of closed-source models from leaderboards."
        ],
        "correct": "Extreme performance convergence, with top models separated by as little as 0.7%.",
            "explanation": "The gap between the top two models on the Chatbot Arena Leaderboard shrank to just 0.7% in 2024[cite: 131].",
        "topic": "Strategic Trends in Technical Performance"
    },
    {
        "question": "Which hardware-related metric is improving at a rate of 40% annually?",
        "options": [
            "Chip production speed",
            "Energy efficiency of machine learning hardware",
            "The physical size of data centers",
            "The cost of liquid cooling systems"
        ],
        "correct": "Energy efficiency of machine learning hardware",
             "explanation": "While compute needs are rising, the energy efficiency of ML hardware has improved by 40% each year[cite: 116].",
        "topic": "Hardware Mechanics"
    },
    {
        "question": "What is the training compute 'doubling time' for notable AI models as of 2024?",
        "options": [
            "Every 5 months",
            "Every 8 months",
            "Every 12 months",
            "Every 24 months"
        ],
        "correct": "Every 5 months",
              "explanation": "Research indicates that training compute for notable models is doubling approximately every five months[cite: 106].",
        "topic": "Infrastructure and Scaling"
    },
    {
        "question": "In 2024, which country launched a $100 billion semiconductor and infrastructure initiative known as 'Project Transcendence'?",
        "options": [
            "China",
            "The United States",
            "Saudi Arabia",
            "Germany"
        ],
        "correct": "Saudi Arabia",
              "explanation": "Saudi Arabia's Project Transcendence represents a massive $100 billion national AI investment[cite: 55].",
        "topic": "Sovereign Compute and Policy"
    },
    {
        "question": "How did the carbon emissions of training Llama 3.1 405B compare to the earlier GPT-3 model?",
        "options": [
            "They were nearly identical.",
            "Llama 3.1 405B emitted about 15 times more carbon.",
            "GPT-3 emitted more carbon due to less efficient hardware.",
            "Llama 3.1 405B emitted 100 times more carbon."
        ],
        "correct": "Llama 3.1 405B emitted about 15 times more carbon.",
         "explanation": "Llama 3.1 405B emitted 8,930 tons of carbon compared to GPT-3’s 588 tons[cite: 118].",
        "topic": "Environmental Impact"
    },
    {
        "question": "What does the 'saturation' of benchmarks like MMLU signify for the AI research community?",
        "options": [
            "AI has achieved human-level intelligence across all domains.",
            "Existing tests are too easy to differentiate the newest frontier models.",
            "Researchers no longer care about evaluating model performance.",
            "Benchmarks are being phased out in favor of user reviews."
        ],
        "correct": "Existing tests are too easy to differentiate the newest frontier models.",
         "explanation": "Near-perfect scores on traditional tests have pushed researchers to propose harder benchmarks like 'Humanity’s Last Exam'[cite: 136, 137].",
        "topic": "Technical Performance Metrics"
    },
    {
        "question": "Which scientific achievement was specifically highlighted by a 2024 Nobel Prize for its use of deep learning?",
        "options": [
            "The discovery of gravitational waves",
            "The application of AI to protein folding",
            "The invention of the lithium-ion battery",
            "The mapping of the human genome"
        ],
        "correct": "The application of AI to protein folding",
         "explanation": "A 2024 Nobel Prize in Chemistry recognized the transformative role of AI in solving protein folding[cite: 66, 919].",
        "topic": "AI in Science and Medicine"
    },
    {
        "question": "How did the performance gap between top open-weight and closed-weight models change in early 2025?",
        "options": [
            "It widened from 1.7% to 8.0%.",
            "It narrowed from 8.0% to just 1.7%.",
            "It remained flat at 5.4%.",
            "It disappeared entirely (0%)."
        ],
        "correct": "It narrowed from 8.0% to just 1.7%.",
         "explanation": "Open-weight models closed the performance gap with proprietary models significantly over the last year[cite: 125, 126].",
        "topic": "Strategic Trends in Research"
    },
    {
        "question": "What percentage of 'notable' AI models were produced by the industry sector in 2024?",
        "options": [
            "40%",
            "60%",
            "78%",
            "Nearly 90%"
        ],
        "correct": "Nearly 90%",
         "explanation": "Industry's lead in model development grew from 60% in 2023 to nearly 90% in 2024[cite: 62, 95].",
        "topic": "Industry vs. Academia"
    },
    {
        "question": "According to the report, what is the 'success rate' of AI systems on the 'FrontierMath' benchmark?",
        "options": [
            "2%",
            "8.8%",
            "35.5%",
            "74.4%"
        ],
        "correct": "2%",
         "explanation": "FrontierMath is so complex that current AI systems can only solve 2% of its problems[cite: 138].",
        "topic": "Advanced Benchmarking"
    },
    {
        "question": "What trend is observed in the dataset sizes used for training Large Language Models (LLMs)?",
        "options": [
            "They are shrinking as models get more efficient.",
            "They are doubling every eight months.",
            "They have stabilized and are no longer growing.",
            "They are doubling every five months."
        ],
        "correct": "They are doubling every eight months.",
         "explanation": "While compute doubles every 5 months, training dataset sizes are doubling every eight months[cite: 106].",
        "topic": "Infrastructure and Scaling"
    },
    {
        "question": "Which country leads in total AI patents, accounting for nearly 70% of all grants globally as of 2023?",
        "options": [
            "The United States",
            "South Korea",
            "China",
            "Japan"
        ],
        "correct": "China",
         "explanation": "China leads the world in AI patenting, accounting for 69.7% of all grants in 2023[cite: 113].",
        "topic": "Global Competitive Landscape"
    },
    {
        "question": "What is a major limitation of current AI models in 'high-stakes' settings as noted in the report?",
        "options": [
            "They are too slow for real-time use.",
            "They often fail to reliably solve logic tasks even with provably correct solutions.",
            "They cannot generate code in common languages like Python.",
            "They require too much manual data entry."
        ],
        "correct": "They often fail to reliably solve logic tasks even with provably correct solutions.",
         "explanation": "AI models still struggle with precision in reasoning, which limits their effectiveness in settings where errors are critical[cite: 68, 921].",
        "topic": "Technical Challenges"
    },
    {
        "question": "How did the gap between Chinese and U.S. model performance on the HumanEval benchmark change in 2024?",
        "options": [
            "It widened from 3.7 to 31.6 points.",
            "It stayed at 17.5 points.",
            "It narrowed from 31.6 points to near parity at 3.7 points.",
            "Chinese models surpassed U.S. models by 10 points."
        ],
        "correct": "It narrowed from 31.6 points to near parity at 3.7 points.",
         "explanation": "Chinese models have rapidly closed the quality gap with U.S. models across major benchmarks[cite: 40, 129].",
        "topic": "Geopolitical Trends in AI"
    },
    {
        "question": "The FDA approved how many AI-enabled medical devices in 2023?",
        "options": [
            "6",
            "59",
            "122",
            "223"
        ],
        "correct": "223",
         "explanation": "The number of AI-enabled medical devices approved by the FDA reached 223 in 2023, up from just six in 2015[cite: 33, 879].",
        "topic": "AI in Science and Medicine"
    },
    {
        "question": "What trend is emerging in U.S. federal AI regulation?",
        "options": [
            "Agencies are removing regulations to promote growth.",
            "The number of AI-related regulations more than doubled in 2024.",
            "Regulation is now handled by a single 'AI Agency'.",
            "Federal agencies have been banned from using AI."
        ],
        "correct": "The number of AI-related regulations more than doubled in 2024.",
         "explanation": "U.S. federal agencies introduced 59 AI-related regulations in 2024, more than twice the number from 2023[cite: 54, 903].",
        "topic": "Policy and Governance"
    },
    {
        "question": "According to the report summary, which region reports the highest level of public AI optimism (83%)?",
        "options": [
            "The United States",
            "The European Union",
            "China",
            "Canada"
        ],
        "correct": "China",
         "explanation": "A strong majority of the public in China (83%) sees AI as more beneficial than harmful[cite: 47, 896].",
        "topic": "Public Opinion"
    }
,
    {
        "question": "What is the primary objective of the 'test-time compute' reasoning paradigm introduced in 2024?",
        "options": [
            "To reduce the power consumption of models during training.",
            "To allow models to iteratively reason through their outputs during inference.",
            "To automate the creation of synthetic training data.",
            "To encrypt model weights for secure local deployment."
        ],
        "correct": "To allow models to iteratively reason through their outputs during inference.",
         "explanation": "Test-time compute, used in models like OpenAI's o1, allows systems to 'think' longer during the response phase to improve reasoning accuracy[cite: 132, 133].",
        "topic": "Machine Learning Techniques"
    },
    {
        "question": "Which benchmark was specifically designed to test the limits of AI in software engineering by requiring models to solve real-world GitHub issues?",
        "options": [
            "GPQA",
            "MMLU",
            "SWE-bench",
            "HumanEval"
        ],
        "correct": "SWE-bench",
         "explanation": "SWE-bench tests advanced systems on their ability to resolve actual software engineering problems[cite: 875, 121].",
        "topic": "Testing and Evaluation"
    },
    {
        "question": "What significant trend was observed regarding 'open-weight' models in 2024?",
        "options": [
            "They fell significantly further behind closed-weight models.",
            "They nearly disappeared from the market due to training costs.",
            "The performance gap between top open-weight and closed-weight models narrowed to just 1.7%.",
            "They became the only models capable of passing the Turing Test."
        ],
        "correct": "The performance gap between top open-weight and closed-weight models narrowed to just 1.7%.",
         "explanation": "Open-weight models rapidly closed the performance gap with proprietary closed models, dropping from an 8.0% difference to 1.7%[cite: 125, 126].",
        "topic": "Technical Performance Trends"
    },
    {
        "question": "In the context of the 2025 report, what does 'benchmark saturation' refer to?",
        "options": [
            "The excessive number of different benchmarks available.",
            "The point where models achieve near-perfect scores, making the tests ineffective for differentiation.",
            "The high cost of running a model against a specific test suite.",
            "The bias found within the questions of traditional evaluation sets."
        ],
        "correct": "The point where models achieve near-perfect scores, making the tests ineffective for differentiation.",
         "explanation": "Saturation occurs when traditional benchmarks like MMLU become too easy for frontier models, necessitating harder tests[cite: 136].",
        "topic": "Testing and Evaluation"
    },
    {
        "question": "Which new benchmark requires AI to solve complex, PhD-level science questions that often stump non-expert humans?",
        "options": [
            "GPQA",
            "GSM8K",
            "PlanBench",
            "MMMU"
        ],
        "correct": "GPQA",
         "explanation": "GPQA is a challenging benchmark featuring experts-written science questions that are very difficult for non-experts[cite: 875, 121].",
        "topic": "Testing and Evaluation"
    },
    {
        "question": "What trade-off is associated with the enhanced reasoning of the o1 model compared to GPT-4o?",
        "options": [
            "It is 30 times faster but less accurate.",
            "It is six times cheaper but uses more data.",
            "It is six times more expensive and 30 times slower.",
            "It requires significantly less energy despite being slower."
        ],
        "correct": "It is six times more expensive and 30 times slower.",
         "explanation": "While more capable at reasoning, the o1 model is significantly slower and more costly than GPT-4o[cite: 135].",
        "topic": "Technical Performance Trends"
    },
    {
        "question": "What is the current success rate for AI systems on the 'BigCodeBench' coding benchmark?",
        "options": [
            "97%",
            "71.7%",
            "35.5%",
            "8.8%"
        ],
        "correct": "35.5%",
         "explanation": "On BigCodeBench, AI systems currently achieve a 35.5% success rate, far below the 97% human standard[cite: 139].",
        "topic": "Testing and Evaluation"
    },
    {
        "question": "Which metric is doubling every five months for notable AI models, according to recent research?",
        "options": [
            "Training compute",
            "Inference speed",
            "Dataset size",
            "Energy efficiency"
        ],
        "correct": "Training compute",
         "explanation": "Training compute requirements for notable models are doubling approximately every five months[cite: 106].",
        "topic": "Machine Learning Techniques"
    },
    {
        "question": "Which benchmark tests the ability of AI models to perform complex planning and reasoning in high-stakes settings?",
        "options": [
            "SORA",
            "PlanBench",
            "HumanEval",
            "HELM Safety"
        ],
        "correct": "PlanBench",
         "explanation": "PlanBench is a benchmark used to test complex reasoning and planning capabilities[cite: 920].",
        "topic": "Testing and Evaluation"
    },
    {
        "question": "What performance gain was recorded on the SWE-bench for AI systems between 2023 and 2024?",
        "options": [
            "18.8 percentage points",
            "48.9 percentage points",
            "67.3 percentage points",
            "9.3 percentage points"
        ],
        "correct": "67.3 percentage points",
         "explanation": "AI performance on SWE-bench saw a massive leap of 67.3 percentage points in a single year[cite: 876, 123].",
        "topic": "Technical Performance Trends"
    },
    {
        "question": "Which evaluation tool focuses specifically on assessing the factuality and safety of Large Language Models?",
        "options": [
            "BigCodeBench",
            "FACTS",
            "Humanity's Last Exam",
            "FrontierMath"
        ],
        "correct": "FACTS",
         "explanation": "FACTS is one of the newer benchmarks designed to evaluate model factuality and safety[cite: 889].",
        "topic": "Testing and Evaluation"
    },
    {
        "question": "As of early 2025, what is the 'convergence' status of model performance at the frontier?",
        "options": [
            "The top two models are separated by a 12% skill gap.",
            "Performance gaps are widening as one company dominates.",
            "The top two models are separated by just 0.7% on leaderboards.",
            "Most models are now failing traditional tests."
        ],
        "correct": "The top two models are separated by just 0.7% on leaderboards.",
         "explanation": "The AI landscape is increasingly competitive, with the top two models now separated by only 0.7%[cite: 131].",
        "topic": "Technical Performance Trends"
    },
    {
        "question": "Which machine learning training resource is doubling every eight months?",
        "options": [
            "Model parameters",
            "Training datasets",
            "GPU clock speeds",
            "Carbon offset credits"
        ],
        "correct": "Training datasets",
         "explanation": "Dataset sizes for training Large Language Models are doubling every eight months[cite: 106].",
        "topic": "Machine Learning Techniques"
    },
    {
        "question": "What is 'Humanity's Last Exam' designed to measure?",
        "options": [
            "The ability of AI to generate high-quality video.",
            "A model's capacity to solve basic arithmetic.",
            "Rigorous academic knowledge where even top systems currently struggle.",
            "The level of public optimism regarding AI's benefits."
        ],
        "correct": "Rigorous academic knowledge where even top systems currently struggle.",
         "explanation": "Humanity's Last Exam is a rigorous academic test where the top system scores just 8.80%[cite: 137].",
        "topic": "Testing and Evaluation"
    },
    {
        "question": "How has the 'Turing Test' been redefined in the 2025 report?",
        "options": [
            "It is now the primary legal standard for defining AI.",
            "It is no longer an ambitious goal, as it has been surpassed by sophisticated systems.",
            "It has been made harder by adding a physical robotics component.",
            "It is the only test China uses to evaluate its models."
        ],
        "correct": "It is no longer an ambitious goal, as it has been surpassed by sophisticated systems.",
         "explanation": "The Turing Test is no longer considered an ambitious goal for today's sophisticated AI systems[cite: 858].",
        "topic": "Technical Performance Trends"
    },
    {
        "question": "What is the primary function of the 'FrontierMath' benchmark?",
        "options": [
            "To test simple algebra and calculus.",
            "To evaluate AI on extremely complex mathematics problems.",
            "To measure the speed of mathematical computations.",
            "To test AI's ability to explain math to K-12 students."
        ],
        "correct": "To evaluate AI on extremely complex mathematics problems.",
         "explanation": "FrontierMath is a complex benchmark where AI systems solve only 2% of the problems[cite: 138].",
        "topic": "Testing and Evaluation"
    },
    {
        "question": "Which country leads in the total volume of AI research publications and citations as of 2023?",
        "options": [
            "United States",
            "United Kingdom",
            "China",
            "South Korea"
        ],
        "correct": "China",
         "explanation": "China produced 23.2% of AI publications and 22.6% of citations in 2023[cite: 98].",
        "topic": "Machine Learning Techniques"
    },
    {
        "question": "What trend is reported for machine learning hardware energy efficiency?",
        "options": [
            "Efficiency is decreasing as models get larger.",
            "Efficiency has stayed flat for a decade.",
            "Energy efficiency is increasing by 40% annually.",
            "Efficiency only improves when models are smaller."
        ],
        "correct": "Energy efficiency is increasing by 40% annually.",
         "explanation": "Hardware energy efficiency has been improving at a rate of 40% each year[cite: 899, 116].",
        "topic": "Technical Performance Trends"
    },
    {
        "question": "Which specific 2024 model release demonstrated a 142-fold reduction in size while maintaining performance on the MMLU benchmark?",
        "options": [
            "GPT-4o mini",
            "Llama 3.1 8B",
            "Phi-3 Mini",
            "Gemini 1.5 Flash"
        ],
        "correct": "Phi-3 Mini",
        "explanation": "Phi-3 Mini achieved the same 60% MMLU threshold as much larger models, marking a 142-fold size reduction.",
        "topic": "Machine Learning Techniques"
    },
    {
        "question": "What is a major limitation of current AI systems when solving PlanBench tasks?",
        "options": [
            "They take too long to generate text.",
            "They fail to reliably solve logic tasks even with provably correct solutions.",
            "They cannot handle multi-modal inputs like images.",
            "They require constant internet connection to reason."
        ],
        "correct": "They fail to reliably solve logic tasks even with provably correct solutions.",
         "explanation": "AI models still struggle with logic and reasoning tasks in benchmarks like PlanBench, which limits their use where precision is critical[cite: 68, 921].",
        "topic": "Technical Performance Trends"
    }
    ,
     {
        "question": "By what percentage did the performance of AI systems on the GPQA benchmark (PhD-level questions) improve in 2024?",
        "options": [
            "18.8 percentage points",
            "28.4 percentage points",
            "48.9 percentage points",
            "64.4 percentage points"
        ],
        "correct": "48.9 percentage points",
        "explanation": "AI performance on the GPQA benchmark saw a remarkable improvement of 48.9 percentage points in 2024 [1].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "What was the success rate for AI models on the SWE-bench coding benchmark in 2023 compared to the top performance in late 2024?",
        "options": [
            "4.4% in 2023 to 71.7% in 2024",
            "10.2% in 2023 to 35.5% in 2024",
            "15% in 2023 to 92% in 2024",
            "0.3% in 2023 to 7.9% in 2024"
        ],
        "correct": "4.4% in 2023 to 71.7% in 2024",
        "explanation": "AI systems could solve just 4.4% of coding problems on SWE-bench in 2023, a figure that jumped to 71.7% in 2024 with the o3 model [1, 2].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "Which new benchmark released in 2024 is designed to test advanced mathematics like number theory and category theory where top models still struggle?",
        "options": [
            "GSM8K",
            "FrontierMath",
            "MATH",
            "AIME 2024"
        ],
        "correct": "FrontierMath",
        "explanation": "FrontierMath is a complex mathematics benchmark where AI systems solve only 2% to 25.2% of problems [3, 4].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "What trend was observed regarding the performance gap between open-weight and closed-weight models on the Chatbot Arena Leaderboard by early 2025?",
        "options": [
            "The gap widened to 15%",
            "The gap nearly disappeared, narrowing to 1.7%",
            "Open-weight models now outperform closed models by 8%",
            "There is no measurable difference between the two types"
        ],
        "correct": "The gap nearly disappeared, narrowing to 1.7%",
        "explanation": "The performance gap on the Chatbot Arena narrowed from 8.0% in early 2024 to just 1.7% by February 2025 [5].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "On the MMLU benchmark, what was the state-of-the-art score achieved by OpenAI's o1-preview in September 2024?",
        "options": [
            "86.4%",
            "89.8%",
            "92.3%",
            "100%"
        ],
        "correct": "92.3%",
        "explanation": "The highest recorded score on MMLU, 92.3%, was achieved by the o1-preview model in late 2024 [6].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "In the RE-Bench evaluation of AI agents, at what time budget does human expert performance begin to surpass AI performance?",
        "options": [
            "2 hours",
            "8 hours",
            "16 hours",
            "32 hours"
        ],
        "correct": "32 hours",
        "explanation": "As the time budget increases to 32 hours, human experts outscore AI agents by a factor of two to one [7, 8].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "What is 'Humanity's Last Exam' (HLE) intended to address in the AI evaluation landscape?",
        "options": [
            "Basic literacy for AI agents",
            "Saturation of traditional benchmarks like MMLU and GSM8K",
            "The Turing test for consciousness",
            "Primary school level common sense"
        ],
        "correct": "Saturation of traditional benchmarks like MMLU and GSM8K",
        "explanation": "HLE was developed as a more rigorous test because traditional benchmarks have reached saturation [3, 9].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "Which model achieved a perfect 100% score on the HumanEval coding benchmark in 2024?",
        "options": [
            "GPT-4o",
            "DeepSeek-V3",
            "Claude 3.5 Sonnet (HPT)",
            "Llama 3.1 405B"
        ],
        "correct": "Claude 3.5 Sonnet (HPT)",
        "explanation": "Claude 3.5 Sonnet (HPT) is the current leader on HumanEval with a score of 100% [10].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "How did the performance gap between Chinese and U.S. models on the HumanEval benchmark change between 2023 and 2024?",
        "options": [
            "It widened from 10 to 40 percentage points",
            "It remained stable at 17.5 percentage points",
            "It narrowed from 31.6 to 3.7 percentage points",
            "Chinese models now lead by 15 percentage points"
        ],
        "correct": "It narrowed from 31.6 to 3.7 percentage points",
        "explanation": "The performance gap between leading U.S. and Chinese models on HumanEval narrowed from 31.6 to 3.7 percentage points in one year [5].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "What score did the top AI system achieve on 'Humanity's Last Exam' as of the 2025 report?",
        "options": [
            "8.80%",
            "35.50%",
            "71.70%",
            "92.30%"
        ],
        "correct": "8.80%",
        "explanation": "On the rigorous Humanity's Last Exam, the top AI system currently scores only 8.80% [3, 11].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "What percentage of notable AI models in 2024 originated from the industry sector?",
        "options": [
            "40%",
            "60%",
            "75%",
            "90%"
        ],
        "correct": "90%",
        "explanation": "Nearly 90% of notable AI models in 2024 came from industry, a significant increase from 60% in 2023 [12, 13].",
        "topic": "R&D Trends"
    },
    {
        "question": "According to the Epoch AI database, how many notable AI models originated from academia in 2024?",
        "options": [
            "0",
            "12",
            "25",
            "55"
        ],
        "correct": "0",
        "explanation": "In 2024, Epoch AI identified no notable AI models originating solely from academia [13, 14].",
        "topic": "R&D Trends"
    },
    {
        "question": "Which organization has produced the highest cumulative number of notable AI models since 2014?",
        "options": [
            "OpenAI",
            "Meta",
            "Microsoft",
            "Google"
        ],
        "correct": "Google",
        "explanation": "Since 2014, Google has led the industry with 187 notable AI models [15].",
        "topic": "R&D Trends"
    },
    {
        "question": "What was the year-over-year increase in the number of AI-related GitHub projects in 2024?",
        "options": [
            "10.5%",
            "21.3%",
            "40.3%",
            "100%"
        ],
        "correct": "40.3%",
        "explanation": "There was a sharp 40.3% rise in the total number of AI-related GitHub projects in the last year [16].",
        "topic": "R&D Trends"
    },
    {
        "question": "By how much did the cost of querying an AI model equivalent to GPT-3.5 on the MMLU benchmark drop between 2022 and 2024?",
        "options": [
            "2 times",
            "10 times",
            "100 times",
            "Over 280 times"
        ],
        "correct": "Over 280 times",
        "explanation": "The cost dropped from $20.00 to $0.07 per million tokens, a more than 280-fold reduction in 18 months [17, 18].",
        "topic": "R&D Trends"
    },
    {
        "question": "What is the primary concern regarding training on synthetic data as highlighted in the R&D chapter?",
        "options": [
            "It is too expensive to generate",
            "It causes models to hallucinate more",
            "Compounded degradation in output quality from hallucinated content",
            "Lack of variety in the data"
        ],
        "correct": "Compounded degradation in output quality from hallucinated content",
        "explanation": "Models can experience compounded degradation in output quality when training on hallucinated content in datasets [19].",
        "topic": "R&D Trends"
    },
    {
        "question": "Which country accounted for the second-largest share of AI project contributions on GitHub in 2024?",
        "options": [
            "China",
            "India",
            "Germany",
            "United Kingdom"
        ],
        "correct": "India",
        "explanation": "India was the second-largest contributor to GitHub AI projects with 19.9% of the share [20].",
        "topic": "R&D Trends"
    },
    {
        "question": "In 2024, what percentage of notable AI models were launched without their corresponding training code?",
        "options": [
            "16.4%",
            "32.8%",
            "60.7%",
            "90.2%"
        ],
        "correct": "60.7%",
        "explanation": "In 2024, the majority of notable models (60.7%) were launched without corresponding training code [21].",
        "topic": "R&D Trends"
    },
    {
        "question": "What hardware component was most commonly reported for training notable machine learning models as of 2024?",
        "options": [
            "Nvidia V100",
            "Nvidia A100",
            "Nvidia H100",
            "Google TPU v4"
        ],
        "correct": "Nvidia A100",
        "explanation": "As of 2024, the A100 was the most commonly reported hardware, used by 64 models [22].",
        "topic": "R&D Trends"
    },
    {
        "question": "According to the Foundation Model Transparency Index, what was the average transparency score among major developers in May 2024?",
        "options": [
            "37 out of 100",
            "58 out of 100",
            "75 out of 100",
            "89 out of 100"
        ],
        "correct": "58 out of 100",
        "explanation": "The average transparency score increased from 37% in October 2023 to 58% in May 2024 [23-25].",
        "topic": "Responsible AI"
    },
    {
        "question": "The number of reported AI-related incidents tracked by the AI Incident Database reached what total in 2024?",
        "options": [
            "105",
            "131",
            "233",
            "1,278"
        ],
        "correct": "233",
        "explanation": "The AI Incident Database (AIID) tracked 233 reported incidents in 2024 [26].",
        "topic": "Responsible AI"
    },
    {
        "question": "What is a key finding regarding implicit bias in advanced LLMs like GPT-4 and Claude 3 Sonnet?",
        "options": [
            "They are completely free of racial and gender bias",
            "They only show bias when prompted with negative terms",
            "They continue to demonstrate implicit biases despite measures to curb explicit bias",
            "Bias has been eliminated in 2024 models"
        ],
        "correct": "They continue to demonstrate implicit biases despite measures to curb explicit bias",
        "explanation": "Advanced LLMs continue to exhibit implicit biases, such as associating negative terms with Black individuals and favoring men for leadership roles [27, 28].",
        "topic": "Responsible AI"
    },
    {
        "question": "Which new benchmark suite was introduced by Stanford's CRFM to evaluate AI models against standardized safety metrics?",
        "options": [
            "TruthfulQA",
            "HELM Safety",
            "AIR-Bench",
            "HHEM Leaderboard"
        ],
        "correct": "HELM Safety",
        "explanation": "HELM Safety is a benchmarking suite designed to evaluate AI models against responsibility and safety metrics [29].",
        "topic": "Responsible AI"
    },
    {
        "question": "What is the 'infectious jailbreak' phenomenon described in 2024 research?",
        "options": [
            "A virus that infects AI hardware",
            "Compromising a single agent triggers a system-wide failure across a network of agents",
            "A way to steal training data via social engineering",
            "An AI agent that spreads misinformation intentionally"
        ],
        "correct": "Compromising a single agent triggers a system-wide failure across a network of agents",
        "explanation": "Infectious jailbreaks occur when compromising a single agent causes harmful behavior to spread exponentially across others [30].",
        "topic": "Responsible AI"
    },
    {
        "question": "What percentage of surveyed organizations reported experiencing AI-related incidents in 2024?",
        "options": [
            "8%",
            "25%",
            "42%",
            "66%"
        ],
        "correct": "8%",
        "explanation": "A survey of business leaders found that only 8% of organizations reported experiencing AI-related incidents [31].",
        "topic": "Responsible AI"
    },
    {
        "question": "Which category of risk is most commonly mitigated by organizations using AI, according to the McKinsey survey?",
        "options": [
            "Personal/individual privacy",
            "Cybersecurity",
            "Regulatory compliance",
            "Intellectual property infringement"
        ],
        "correct": "Cybersecurity",
        "explanation": "Cybersecurity was selected by 55% of respondents as a mitigated risk, the highest in the survey [32].",
        "topic": "Responsible AI"
    },
    {
        "question": "What trend was noted regarding data consent protocols for AI training between 2023 and 2024?",
        "options": [
            "Websites became more open to data scraping",
            "There was no change in robots.txt usage",
            "Significant increase in data use restrictions via robots.txt and terms of service",
            "Legal cases led to the elimination of all data scraping restrictions"
        ],
        "correct": "Significant increase in data use restrictions via robots.txt and terms of service",
        "explanation": "Researchers observed a significant increase in data use restrictions as websites implemented new protocols to limit AI data scraping [33].",
        "topic": "Responsible AI"
    },
    {
        "question": "How did the number of Responsible AI (RAI) papers at leading academic conferences change in 2024?",
        "options": [
            "Decreased by 10%",
            "Stayed flat",
            "Increased by 28.8%",
            "Quadrupled"
        ],
        "correct": "Increased by 28.8%",
        "explanation": "The number of RAI papers accepted at leading conferences rose by 28.8% in 2024 [28, 34].",
        "topic": "Responsible AI"
    },
    {
        "question": "Which AI skill cluster saw the largest increase in U.S. labor market share in 2024?",
        "options": [
            "Machine Learning",
            "Natural Language Processing",
            "Generative AI",
            "Robotics"
        ],
        "correct": "Generative AI",
        "explanation": "Generative AI saw the largest increase in market share among AI skill clusters, growing by nearly a factor of four [35].",
        "topic": "AI Economy"
    },
    {
        "question": "What is the 'equalizing effect' of AI on workplace performance identified in several 2024 studies?",
        "options": [
            "AI makes all employees earn the same salary",
            "Low-skill workers see higher productivity gains than high-skill workers",
            "AI replaces humans at equal rates across all industries",
            "AI tools work equally well on all hardware"
        ],
        "correct": "Low-skill workers see higher productivity gains than high-skill workers",
        "explanation": "A consistent pattern is that AI tools boost the productivity of low-skill or junior workers more significantly than high-skill workers [36, 37].",
        "topic": "AI Economy"
    },
    {
        "question": "Which country had the greatest relative AI hiring rate vibrancy in 2024?",
        "options": [
            "United States",
            "Brazil",
            "Saudi Arabia",
            "India"
        ],
        "correct": "India",
        "explanation": "In 2024, India experienced the most significant rise in AI talent recruitment vibrancy at 33.4% [38, 39].",
        "topic": "AI Economy"
    },
    {
        "question": "According to the Anthropic study, which occupation group accounts for the highest percentage of Claude AI conversations (37.2%)?",
        "options": [
            "Office and administrative support",
            "Legal",
            "Computer and mathematical",
            "Arts, design, and media"
        ],
        "correct": "Computer and mathematical",
        "explanation": "Computer and mathematical occupations dominate Claude usage, accounting for 37.2% of all AI interactions [40].",
        "topic": "AI Economy"
    },
    {
        "question": "What percentage of business leaders reported that their organizations' generative AI rollouts were 'mature'?",
        "options": [
            "1%",
            "15%",
            "33%",
            "72%"
        ],
        "correct": "1%",
        "explanation": "A survey of C-suite executives found that only 1% described their generative AI rollouts as 'mature' [41].",
        "topic": "AI Economy"
    },
    {
        "question": "In terms of cost savings from generative AI, which business function reported the highest percentage of savings (61%)?",
        "options": [
            "Human Resources",
            "Marketing and Sales",
            "Supply chain and inventory management",
            "IT"
        ],
        "correct": "Supply chain and inventory management",
        "explanation": "The area where respondents most frequently reported cost savings from generative AI was supply chain and inventory management at 61% [42, 43].",
        "topic": "AI Economy"
    },
    {
        "question": "What was the state-of-the-art score set by o1 on the MedQA benchmark for clinical knowledge in late 2024?",
        "options": [
            "78.2%",
            "81.3%",
            "92.3%",
            "96.0%"
        ],
        "correct": "96.0%",
        "explanation": "OpenAI's o1 set a new state-of-the-art score of 96.0% on the MedQA benchmark [44-46].",
        "topic": "Science & Medicine"
    },
    {
        "question": "The number of publications on ethics in medical AI saw what change between 2020 and 2024?",
        "options": [
            "Decreased due to regulation",
            "Doubled",
            "Quadrupled",
            "Remained unchanged"
        ],
        "correct": "Quadrupled",
        "explanation": "The number of publications on ethics in medical AI quadrupled, rising from 288 in 2020 to 1,031 in 2024 [47-49].",
        "topic": "Science & Medicine"
    },
    {
        "question": "What is the primary function of Google's FireSat AI system released in 2024?",
        "options": [
            "Predicting sunspots",
            "Detecting wildfires as small as 5x5 meters within 20 minutes",
            "Simulating protein stability",
            "Analyzing clinical risk in hospitals"
        ],
        "correct": "Detecting wildfires as small as 5x5 meters within 20 minutes",
        "explanation": "FireSat is a satellite-based wildfire detection system that identifies fires as small as 5x5 meters very quickly [44, 50].",
        "topic": "Science & Medicine"
    },
    {
        "question": "Which medical imaging domain had the highest concentration of newly launched foundation models in 2024?",
        "options": [
            "Ophthalmology",
            "Radiology",
            "Pathology",
            "Echocardiology"
        ],
        "correct": "Pathology",
        "explanation": "In 2024, there was a particularly high concentration of newly launched pathology models, such as CHIEF and Virchow [51].",
        "topic": "Science & Medicine"
    },
    {
        "question": "What milestone did the ESM3 model achieve regarding protein engineering in 2024?",
        "options": [
            "Predicting every human protein structure",
            "Designing a new artificial green fluorescent protein (esmGFP)",
            "Curing a specific rare disease in simulation",
            "Creating the first digital twin of a human brain"
        ],
        "correct": "Designing a new artificial green fluorescent protein (esmGFP)",
        "explanation": "ESM3's most notable achievement was designing esmGFP, a fluorescent protein estimated to take nature 500 million years to develop [52].",
        "topic": "Science & Medicine"
    },
    {
        "question": "How much more training data (tokens) did the general-purpose Llama 3 model use compared to the GatorTron medical model?",
        "options": [
            "They used the same amount",
            "Llama 3 used twice as much",
            "Llama 3 used nearly 182 times more tokens",
            "GatorTron used more data to ensure precision"
        ],
        "correct": "Llama 3 used nearly 182 times more tokens",
        "explanation": "Llama 3 was trained on 15 trillion tokens, nearly 182 times more than GatorTron's 82 billion tokens [53, 54].",
        "topic": "Science & Medicine"
    },
    {
        "question": "The number of AI-related regulations in U.S. federal agencies saw what growth in 2024?",
        "options": [
            "Decreased by 50%",
            "Stayed at 25 regulations",
            "More than doubled from 25 to 59",
            "Rose to over 500 regulations"
        ],
        "correct": "More than doubled from 25 to 59",
        "explanation": "The number of AI-related regulations in U.S. federal agencies more than doubled, increasing from 25 to 59 in 2024 [55].",
        "topic": "Policy & Governance"
    },
    {
        "question": "What major AI legislation was passed by the European Parliament in June 2024?",
        "options": [
            "The Brussels AI Directive",
            "The EU AI Act",
            "The GDPR-AI Amendment",
            "The European Machine Learning Law"
        ],
        "correct": "The EU AI Act",
        "explanation": "The EU AI Act, a milestone in global legislation, was passed by the European Parliament in June 2024 [55].",
        "topic": "Policy & Governance"
    },
    {
        "question": "In the United States, how many states had passed regulations targeting deepfakes by late 2024?",
        "options": [
            "5",
            "15",
            "24",
            "50"
        ],
        "correct": "24",
        "explanation": "By 2024, 24 states in the U.S. had passed regulations specifically targeting deepfakes [55, 56].",
        "topic": "Policy & Governance"
    },
    {
        "question": "What is the 'Project Transcendence' investment figure announced by Saudi Arabia in 2024?",
        "options": [
            "2.4 billion dollars",
            "10 billion dollars",
            "47.5 billion dollars",
            "100 billion dollars"
        ],
        "correct": "100 billion dollars",
        "explanation": "Saudi Arabia announced a 100 billion dollar project named 'Project Transcendence' for AI infrastructure [55].",
        "topic": "Policy & Governance"
    },
    {
        "question": "Which U.S. government agency received the largest share of public AI grant funding between 2013 and 2023?",
        "options": [
            "Department of Defense",
            "National Science Foundation",
            "Department of Health and Human Services",
            "Department of Energy"
        ],
        "correct": "Department of Health and Human Services",
        "explanation": "The Department of Health and Human Services allocated the greatest share of U.S. AI-related grants at 43.6% [57].",
        "topic": "Policy & Governance"
    },
    {
        "question": "What fraction of countries worldwide now offer or plan to offer K-12 Computer Science (CS) education?",
        "options": [
            "One-quarter",
            "One-third",
            "One-half",
            "Two-thirds"
        ],
        "correct": "Two-thirds",
        "explanation": "Two-thirds of countries now offer or plan to offer K-12 Computer Science education, a fraction that has doubled since 2019 [58-60].",
        "topic": "AI Education"
    },
    {
        "question": "What is a primary barrier to K-12 Computer Science education in many African countries, as noted in the report?",
        "options": [
            "Lack of teachers",
            "Lack of student interest",
            "Infrastructure gaps like lack of electricity",
            "Religious opposition"
        ],
        "correct": "Infrastructure gaps like lack of electricity",
        "explanation": "Students in African countries often lack access to CS education due to school-level infrastructure gaps like electricity [58-60].",
        "topic": "AI Education"
    },
    {
        "question": "What trend was observed regarding AI-specific master's degree graduates in the U.S. between 2022 and 2023?",
        "options": [
            "The number decreased by half",
            "The number nearly doubled",
            "The number stayed the same",
            "AI master's degrees were eliminated in favor of PhDs"
        ],
        "correct": "The number nearly doubled",
        "explanation": "Graduates who earned their master's degree in AI in the U.S. nearly doubled between 2022 and 2023 [61, 62].",
        "topic": "AI Education"
    },
    {
        "question": "Despite 81% of U.S. teachers wanting AI in foundational CS education, how many feel equipped to teach it?",
        "options": [
            "Less than 10%",
            "About 25%",
            "Less than half",
            "Nearly all"
        ],
        "correct": "Less than half",
        "explanation": "While 81% of teachers agree AI should be taught, less than half feel equipped to teach AI [58-60, 63].",
        "topic": "AI Education"
    },
    {
        "question": "Which country produces the most ICT graduates globally across the associate, bachelor's, master's, and PhD levels?",
        "options": [
            "China",
            "India",
            "United States",
            "Brazil"
        ],
        "correct": "United States",
        "explanation": "The U.S. continues to be a global leader in producing ICT graduates at all degree levels [61, 64, 65].",
        "topic": "AI Education"
    },
    {
        "question": "What percentage of U.S. universities have an AI-related acceptable use policy as of early 2025?",
        "options": [
            "10%",
            "23%",
            "39%",
            "86%"
        ],
        "correct": "39%",
        "explanation": "As of early 2025, 39% of higher education institutions have an AI-related acceptable use policy, up from 23% in 2024 [66].",
        "topic": "AI Education"
    },
    {
        "question": "According to global public opinion, what percentage of people expect AI to save them time?",
        "options": [
            "13%",
            "36%",
            "55%",
            "83%"
        ],
        "correct": "55%",
        "explanation": "Globally, 55% of respondents agreed that AI will save them time [67, 68].",
        "topic": "Public Opinion"
    },
    {
        "question": "In which country is the public most optimistic about the benefits of AI products (83% agreeing benefits outweigh drawbacks)?",
        "options": [
            "USA",
            "Canada",
            "China",
            "Germany"
        ],
        "correct": "China",
        "explanation": "China shows the highest public optimism regarding AI, with 83% agreeing its benefits outweigh drawbacks [68-70].",
        "topic": "Public Opinion"
    },
    {
        "question": "What is the sentiment among U.S. citizens regarding self-driving cars according to the American Automobile Association?",
        "options": [
            "61% trust them",
            "61% fear them",
            "Only 5% are aware of them",
            "Fear has peaked at 90% in 2024"
        ],
        "correct": "61% fear them",
        "explanation": "The AAA survey found that 61% of people in the U.S. fear self-driving cars, while only 13% trust them [71].",
        "topic": "Public Opinion"
    },
    {
        "question": "How did carbon emissions from training notable AI models change from GPT-3 (2020) to Llama 3.1 405B (2024)?",
        "options": [
            "Emissions decreased due to efficiency",
            "Emissions rose from 588 tons to 8,930 tons",
            "GPT-4 remains the highest emitter at 5,184 tons",
            "Modern models have nearly zero carbon footprint"
        ],
        "correct": "Emissions rose from 588 tons to 8,930 tons",
        "explanation": "Carbon emissions from training rose from 588 tons for GPT-3 to 8,930 tons for Llama 3.1 405B [72, 73].",
        "topic": "Scale & Infrastructure"
    },
    {
        "question": "What is the reported annual growth rate of training compute for notable AI models?",
        "options": [
            "Compute doubles every month",
            "Compute doubles every five months",
            "Compute doubles every two years",
            "Compute has plateaued in 2024"
        ],
        "correct": "Compute doubles every five months",
        "explanation": "The report states that training compute for notable models doubles every five months [12].",
        "topic": "Scale & Infrastructure"
    },
    {
        "question": "Which major tech company announced a 1.6 billion dollar deal to revive a nuclear reactor at Three Mile Island to power data centers?",
        "options": [
            "Google",
            "Meta",
            "Amazon",
            "Microsoft"
        ],
        "correct": "Microsoft",
        "explanation": "Microsoft announced a deal with Constellation Energy to revive the Three Mile Island nuclear reactor [74].",
        "topic": "Scale & Infrastructure"
    },
    {
        "question": "What was the estimated training cost of OpenAI's GPT-4 according to AI Index estimates?",
        "options": [
            "670 dollars",
            "160,000 dollars",
            "79 million dollars",
            "1 billion dollars"
        ],
        "correct": "79 million dollars",
        "explanation": "The training costs for OpenAI's GPT-4 were estimated to be around 79 million dollars [75, 76].",
        "topic": "Scale & Infrastructure"
    },
    {
        "question": "How much power did the Llama 3.1 405B model require for training compared to the original 2017 Transformer?",
        "options": [
            "The same amount",
            "10 times more",
            "100 times more",
            "Over 5,000 times more"
        ],
        "correct": "Over 5,000 times more",
        "explanation": "Llama 3.1 405B used 25.3 million watts, over 5,000 times more than the 2017 Transformer [72].",
        "topic": "Scale & Infrastructure"
    },
    {
        "question": "What new model reasoning paradigm introduced by OpenAI in 2024 uses 'inference-time compute' to iteratively check answers?",
        "options": [
            "GPT-4o",
            "The 'o series' (o1, o3)",
            "Llama 3.1",
            "Claude 3.5"
        ],
        "correct": "The 'o series' (o1, o3)",
        "explanation": "The o1 and o3 models are designed to iteratively reason through their outputs using test-time compute [77-79].",
        "topic": "New Paradigms"
    },
    {
        "question": "What is the primary drawback of models using inference-time compute like o1 compared to standard models like GPT-4o?",
        "options": [
            "They are less accurate",
            "They are cheaper but slower",
            "They are significantly more expensive and 30 times slower",
            "They cannot process text"
        ],
        "correct": "They are significantly more expensive and 30 times slower",
        "explanation": "While they improve reasoning, o1 models are nearly six times more expensive and 30 times slower than GPT-4o [78, 80].",
        "topic": "New Paradigms"
    },
    {
        "question": "Which 2024 model released by Nvidia achieved top scores on vision-language tasks like OCRBench?",
        "options": [
            "Llama 3.3",
            "Gemini 2.0",
            "NVLM (D, H, X)",
            "Stable Video 4D"
        ],
        "correct": "NVLM (D, H, X)",
        "explanation": "Nvidia released three NVLM models for vision-language tasks achieving top scores on OCRBench [81].",
        "topic": "New Paradigms"
    },
    {
        "question": "The 'Computer Use' agentic capability released in late 2024 allows which model to move the cursor and autonomously complete tasks?",
        "options": [
            "GPT-4o",
            "Claude 3.5 Sonnet",
            "Gemini 1.5 Pro",
            "Llama 3.1"
        ],
        "correct": "Claude 3.5 Sonnet",
        "explanation": "Anthropic's 'Computer Use' feature allows Claude 3.5 Sonnet to autonomously complete tasks on a user's computer [82].",
        "topic": "New Paradigms"
    },
    {
        "question": "What architectural improvement does the Falcon Mamba model utilize to be more efficient than standard transformer-based models?",
        "options": [
            "Liquid Neural Networks",
            "State Space Language Model (SSLM)",
            "Recurrent Convolutional Nets",
            "Quantum-inspired gates"
        ],
        "correct": "State Space Language Model (SSLM)",
        "explanation": "Falcon Mamba is built on the SSLM architecture, making it more efficient than traditional transformer models [83].",
        "topic": "New Paradigms"
    },
    {
        "question": "According to the BetterBench study, how many prominent AI benchmarks failed to report statistical significance?",
        "options": [
            "0",
            "5 out of 24",
            "14 out of 24",
            "All of them"
        ],
        "correct": "14 out of 24",
        "explanation": "A systematic analysis of 24 benchmarks found that 14 failed to report statistical significance [84].",
        "topic": "Technical Benchmarks"
    },
    {
        "question": "What was the observed drop in inference cost for PhD-level science questions (GPQA Diamond) between 2022 and 2024?",
        "options": [
            "5 times cheaper",
            "9 times cheaper",
            "Over 100 times cheaper",
            "There was no drop"
        ],
        "correct": "9 times cheaper",
        "explanation": "The report notes that depending on the task, inference prices have fallen anywhere from 9 to 900 times per year [17, 18].",
        "topic": "R&D Trends"
    },
    {
        "question": "Which country had the highest percentage of AI publications originating from the education sector (84.5%)?",
        "options": [
            "USA",
            "China",
            "United Kingdom",
            "India"
        ],
        "correct": "China",
        "explanation": "China has the highest percentage of AI publications (84.45%) originating from the education sector [85].",
        "topic": "R&D Trends"
    },
    {
        "question": "In the context of AI safety, what is 'shallow safety alignment'?",
        "options": [
            "Training only a small part of the model",
            "A model's safeguards being limited to the first few words of a response",
            "Safety alignment that only works in English",
            "Models that refuse every prompt"
        ],
        "correct": "A model's safeguards being limited to the first few words of a response",
        "explanation": "Shallow safety alignment is the concept that safeguards are often limited to the first few tokens, making models vulnerable to adversarial attacks [86].",
        "topic": "Responsible AI"
    },
    {
        "question": "What percentage of U.S. high schools offered Computer Science courses in the 2023-24 school year?",
        "options": [
            "15%",
            "35%",
            "60%",
            "100%"
        ],
        "correct": "60%",
        "explanation": "Access to CS education has increased from 35% in 2017-18 to 60% of U.S. high schools in 2023-24 [87].",
        "topic": "AI Education"
    }
]